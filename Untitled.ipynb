{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = pd.read_csv(\"dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording_time_ID</th>\n",
       "      <th>lhx</th>\n",
       "      <th>lhy</th>\n",
       "      <th>lhz</th>\n",
       "      <th>rhx</th>\n",
       "      <th>rhy</th>\n",
       "      <th>rhz</th>\n",
       "      <th>hx</th>\n",
       "      <th>hy</th>\n",
       "      <th>hz</th>\n",
       "      <th>...</th>\n",
       "      <th>arhx</th>\n",
       "      <th>arhy</th>\n",
       "      <th>arhz</th>\n",
       "      <th>alwx</th>\n",
       "      <th>alwy</th>\n",
       "      <th>alwz</th>\n",
       "      <th>arwx</th>\n",
       "      <th>arwy</th>\n",
       "      <th>arwz</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR0888</td>\n",
       "      <td>4.205590</td>\n",
       "      <td>4.694525</td>\n",
       "      <td>1.869073</td>\n",
       "      <td>4.921949</td>\n",
       "      <td>4.029522</td>\n",
       "      <td>1.889851</td>\n",
       "      <td>4.851381</td>\n",
       "      <td>1.856576</td>\n",
       "      <td>2.092771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>3.774520e-03</td>\n",
       "      <td>5.399800e-04</td>\n",
       "      <td>1.797380e-03</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-7.289700e-04</td>\n",
       "      <td>7.043100e-04</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>4.028200e-04</td>\n",
       "      <td>Response-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR1820</td>\n",
       "      <td>3.667537</td>\n",
       "      <td>5.315720</td>\n",
       "      <td>1.828394</td>\n",
       "      <td>5.496964</td>\n",
       "      <td>5.049758</td>\n",
       "      <td>1.650158</td>\n",
       "      <td>4.452520</td>\n",
       "      <td>1.847379</td>\n",
       "      <td>1.981042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>9.019000e-04</td>\n",
       "      <td>6.443000e-05</td>\n",
       "      <td>-2.201000e-05</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-9.400000e-07</td>\n",
       "      <td>3.954800e-04</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>6.380000e-05</td>\n",
       "      <td>Response-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR1873</td>\n",
       "      <td>3.687988</td>\n",
       "      <td>2.772793</td>\n",
       "      <td>1.626460</td>\n",
       "      <td>6.565267</td>\n",
       "      <td>2.711560</td>\n",
       "      <td>1.630421</td>\n",
       "      <td>5.026713</td>\n",
       "      <td>1.773879</td>\n",
       "      <td>1.677735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-1.383200e-03</td>\n",
       "      <td>4.241600e-04</td>\n",
       "      <td>-5.700100e-04</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>2.262100e-04</td>\n",
       "      <td>8.658100e-04</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>3.404000e-04</td>\n",
       "      <td>Response-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR4378</td>\n",
       "      <td>4.726025</td>\n",
       "      <td>4.561223</td>\n",
       "      <td>1.902970</td>\n",
       "      <td>6.186168</td>\n",
       "      <td>4.496355</td>\n",
       "      <td>1.858916</td>\n",
       "      <td>4.920242</td>\n",
       "      <td>1.872385</td>\n",
       "      <td>2.126026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>7.901100e-04</td>\n",
       "      <td>-1.390000e-05</td>\n",
       "      <td>1.242400e-04</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>4.246000e-05</td>\n",
       "      <td>4.017000e-05</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>9.127000e-05</td>\n",
       "      <td>Response-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR3139</td>\n",
       "      <td>2.289227</td>\n",
       "      <td>4.712777</td>\n",
       "      <td>2.227426</td>\n",
       "      <td>2.993593</td>\n",
       "      <td>4.458786</td>\n",
       "      <td>2.288884</td>\n",
       "      <td>2.370949</td>\n",
       "      <td>0.869894</td>\n",
       "      <td>2.407945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-1.500000e-07</td>\n",
       "      <td>2.600000e-07</td>\n",
       "      <td>7.100000e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.600000e-07</td>\n",
       "      <td>5.400000e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>6.500000e-07</td>\n",
       "      <td>Response-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Recording_time_ID       lhx       lhy       lhz       rhx       rhy  \\\n",
       "0            AR0888  4.205590  4.694525  1.869073  4.921949  4.029522   \n",
       "1            AR1820  3.667537  5.315720  1.828394  5.496964  5.049758   \n",
       "2            AR1873  3.687988  2.772793  1.626460  6.565267  2.711560   \n",
       "3            AR4378  4.726025  4.561223  1.902970  6.186168  4.496355   \n",
       "4            AR3139  2.289227  4.712777  2.227426  2.993593  4.458786   \n",
       "\n",
       "        rhz        hx        hy        hz  ...      arhx          arhy  \\\n",
       "0  1.889851  4.851381  1.856576  2.092771  ...  0.000940  3.774520e-03   \n",
       "1  1.650158  4.452520  1.847379  1.981042  ...  0.001386  9.019000e-04   \n",
       "2  1.630421  5.026713  1.773879  1.677735  ...  0.000232 -1.383200e-03   \n",
       "3  1.858916  4.920242  1.872385  2.126026  ...  0.000949  7.901100e-04   \n",
       "4  2.288884  2.370949  0.869894  2.407945  ...  0.000001 -1.500000e-07   \n",
       "\n",
       "           arhz          alwx      alwy          alwz          arwx      arwy  \\\n",
       "0  5.399800e-04  1.797380e-03 -0.000401 -7.289700e-04  7.043100e-04  0.002726   \n",
       "1  6.443000e-05 -2.201000e-05 -0.000018 -9.400000e-07  3.954800e-04  0.000107   \n",
       "2  4.241600e-04 -5.700100e-04 -0.003331  2.262100e-04  8.658100e-04 -0.002652   \n",
       "3 -1.390000e-05  1.242400e-04 -0.000161  4.246000e-05  4.017000e-05  0.000250   \n",
       "4  2.600000e-07  7.100000e-07  0.000003 -1.600000e-07  5.400000e-07 -0.000002   \n",
       "\n",
       "           arwz      Action  \n",
       "0  4.028200e-04  Response-3  \n",
       "1  6.380000e-05  Response-5  \n",
       "2  3.404000e-04  Response-3  \n",
       "3  9.127000e-05  Response-5  \n",
       "4  6.500000e-07  Response-1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response-3    175\n",
       "Response-1    152\n",
       "Response-2    124\n",
       "Response-5     71\n",
       "Response-4     70\n",
       "Name: Action, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_orig['Action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_orig.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lhx</th>\n",
       "      <th>lhy</th>\n",
       "      <th>lhz</th>\n",
       "      <th>rhx</th>\n",
       "      <th>rhy</th>\n",
       "      <th>rhz</th>\n",
       "      <th>hx</th>\n",
       "      <th>hy</th>\n",
       "      <th>hz</th>\n",
       "      <th>sx</th>\n",
       "      <th>...</th>\n",
       "      <th>arhx</th>\n",
       "      <th>arhy</th>\n",
       "      <th>arhz</th>\n",
       "      <th>alwx</th>\n",
       "      <th>alwy</th>\n",
       "      <th>alwz</th>\n",
       "      <th>arwx</th>\n",
       "      <th>arwy</th>\n",
       "      <th>arwz</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.205590</td>\n",
       "      <td>4.694525</td>\n",
       "      <td>1.869073</td>\n",
       "      <td>4.921949</td>\n",
       "      <td>4.029522</td>\n",
       "      <td>1.889851</td>\n",
       "      <td>4.851381</td>\n",
       "      <td>1.856576</td>\n",
       "      <td>2.092771</td>\n",
       "      <td>4.847641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>3.774520e-03</td>\n",
       "      <td>5.399800e-04</td>\n",
       "      <td>1.797380e-03</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-7.289700e-04</td>\n",
       "      <td>7.043100e-04</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>4.028200e-04</td>\n",
       "      <td>Response-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.667537</td>\n",
       "      <td>5.315720</td>\n",
       "      <td>1.828394</td>\n",
       "      <td>5.496964</td>\n",
       "      <td>5.049758</td>\n",
       "      <td>1.650158</td>\n",
       "      <td>4.452520</td>\n",
       "      <td>1.847379</td>\n",
       "      <td>1.981042</td>\n",
       "      <td>4.470696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>9.019000e-04</td>\n",
       "      <td>6.443000e-05</td>\n",
       "      <td>-2.201000e-05</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-9.400000e-07</td>\n",
       "      <td>3.954800e-04</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>6.380000e-05</td>\n",
       "      <td>Response-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.687988</td>\n",
       "      <td>2.772793</td>\n",
       "      <td>1.626460</td>\n",
       "      <td>6.565267</td>\n",
       "      <td>2.711560</td>\n",
       "      <td>1.630421</td>\n",
       "      <td>5.026713</td>\n",
       "      <td>1.773879</td>\n",
       "      <td>1.677735</td>\n",
       "      <td>5.099942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-1.383200e-03</td>\n",
       "      <td>4.241600e-04</td>\n",
       "      <td>-5.700100e-04</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>2.262100e-04</td>\n",
       "      <td>8.658100e-04</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>3.404000e-04</td>\n",
       "      <td>Response-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.726025</td>\n",
       "      <td>4.561223</td>\n",
       "      <td>1.902970</td>\n",
       "      <td>6.186168</td>\n",
       "      <td>4.496355</td>\n",
       "      <td>1.858916</td>\n",
       "      <td>4.920242</td>\n",
       "      <td>1.872385</td>\n",
       "      <td>2.126026</td>\n",
       "      <td>4.854091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>7.901100e-04</td>\n",
       "      <td>-1.390000e-05</td>\n",
       "      <td>1.242400e-04</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>4.246000e-05</td>\n",
       "      <td>4.017000e-05</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>9.127000e-05</td>\n",
       "      <td>Response-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.289227</td>\n",
       "      <td>4.712777</td>\n",
       "      <td>2.227426</td>\n",
       "      <td>2.993593</td>\n",
       "      <td>4.458786</td>\n",
       "      <td>2.288884</td>\n",
       "      <td>2.370949</td>\n",
       "      <td>0.869894</td>\n",
       "      <td>2.407945</td>\n",
       "      <td>2.484432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-1.500000e-07</td>\n",
       "      <td>2.600000e-07</td>\n",
       "      <td>7.100000e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.600000e-07</td>\n",
       "      <td>5.400000e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>6.500000e-07</td>\n",
       "      <td>Response-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lhx       lhy       lhz       rhx       rhy       rhz        hx  \\\n",
       "0  4.205590  4.694525  1.869073  4.921949  4.029522  1.889851  4.851381   \n",
       "1  3.667537  5.315720  1.828394  5.496964  5.049758  1.650158  4.452520   \n",
       "2  3.687988  2.772793  1.626460  6.565267  2.711560  1.630421  5.026713   \n",
       "3  4.726025  4.561223  1.902970  6.186168  4.496355  1.858916  4.920242   \n",
       "4  2.289227  4.712777  2.227426  2.993593  4.458786  2.288884  2.370949   \n",
       "\n",
       "         hy        hz        sx  ...      arhx          arhy          arhz  \\\n",
       "0  1.856576  2.092771  4.847641  ...  0.000940  3.774520e-03  5.399800e-04   \n",
       "1  1.847379  1.981042  4.470696  ...  0.001386  9.019000e-04  6.443000e-05   \n",
       "2  1.773879  1.677735  5.099942  ...  0.000232 -1.383200e-03  4.241600e-04   \n",
       "3  1.872385  2.126026  4.854091  ...  0.000949  7.901100e-04 -1.390000e-05   \n",
       "4  0.869894  2.407945  2.484432  ...  0.000001 -1.500000e-07  2.600000e-07   \n",
       "\n",
       "           alwx      alwy          alwz          arwx      arwy          arwz  \\\n",
       "0  1.797380e-03 -0.000401 -7.289700e-04  7.043100e-04  0.002726  4.028200e-04   \n",
       "1 -2.201000e-05 -0.000018 -9.400000e-07  3.954800e-04  0.000107  6.380000e-05   \n",
       "2 -5.700100e-04 -0.003331  2.262100e-04  8.658100e-04 -0.002652  3.404000e-04   \n",
       "3  1.242400e-04 -0.000161  4.246000e-05  4.017000e-05  0.000250  9.127000e-05   \n",
       "4  7.100000e-07  0.000003 -1.600000e-07  5.400000e-07 -0.000002  6.500000e-07   \n",
       "\n",
       "       Action  \n",
       "0  Response-3  \n",
       "1  Response-5  \n",
       "2  Response-3  \n",
       "3  Response-5  \n",
       "4  Response-1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data.iloc[:,42] = label_encoder.fit_transform(data.iloc[:,42]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lhx</th>\n",
       "      <th>lhy</th>\n",
       "      <th>lhz</th>\n",
       "      <th>rhx</th>\n",
       "      <th>rhy</th>\n",
       "      <th>rhz</th>\n",
       "      <th>hx</th>\n",
       "      <th>hy</th>\n",
       "      <th>hz</th>\n",
       "      <th>sx</th>\n",
       "      <th>...</th>\n",
       "      <th>arhx</th>\n",
       "      <th>arhy</th>\n",
       "      <th>arhz</th>\n",
       "      <th>alwx</th>\n",
       "      <th>alwy</th>\n",
       "      <th>alwz</th>\n",
       "      <th>arwx</th>\n",
       "      <th>arwy</th>\n",
       "      <th>arwz</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.205590</td>\n",
       "      <td>4.694525</td>\n",
       "      <td>1.869073</td>\n",
       "      <td>4.921949</td>\n",
       "      <td>4.029522</td>\n",
       "      <td>1.889851</td>\n",
       "      <td>4.851381</td>\n",
       "      <td>1.856576</td>\n",
       "      <td>2.092771</td>\n",
       "      <td>4.847641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>3.774520e-03</td>\n",
       "      <td>5.399800e-04</td>\n",
       "      <td>1.797380e-03</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-7.289700e-04</td>\n",
       "      <td>7.043100e-04</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>4.028200e-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.667537</td>\n",
       "      <td>5.315720</td>\n",
       "      <td>1.828394</td>\n",
       "      <td>5.496964</td>\n",
       "      <td>5.049758</td>\n",
       "      <td>1.650158</td>\n",
       "      <td>4.452520</td>\n",
       "      <td>1.847379</td>\n",
       "      <td>1.981042</td>\n",
       "      <td>4.470696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>9.019000e-04</td>\n",
       "      <td>6.443000e-05</td>\n",
       "      <td>-2.201000e-05</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-9.400000e-07</td>\n",
       "      <td>3.954800e-04</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>6.380000e-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.687988</td>\n",
       "      <td>2.772793</td>\n",
       "      <td>1.626460</td>\n",
       "      <td>6.565267</td>\n",
       "      <td>2.711560</td>\n",
       "      <td>1.630421</td>\n",
       "      <td>5.026713</td>\n",
       "      <td>1.773879</td>\n",
       "      <td>1.677735</td>\n",
       "      <td>5.099942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-1.383200e-03</td>\n",
       "      <td>4.241600e-04</td>\n",
       "      <td>-5.700100e-04</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>2.262100e-04</td>\n",
       "      <td>8.658100e-04</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>3.404000e-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.726025</td>\n",
       "      <td>4.561223</td>\n",
       "      <td>1.902970</td>\n",
       "      <td>6.186168</td>\n",
       "      <td>4.496355</td>\n",
       "      <td>1.858916</td>\n",
       "      <td>4.920242</td>\n",
       "      <td>1.872385</td>\n",
       "      <td>2.126026</td>\n",
       "      <td>4.854091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>7.901100e-04</td>\n",
       "      <td>-1.390000e-05</td>\n",
       "      <td>1.242400e-04</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>4.246000e-05</td>\n",
       "      <td>4.017000e-05</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>9.127000e-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.289227</td>\n",
       "      <td>4.712777</td>\n",
       "      <td>2.227426</td>\n",
       "      <td>2.993593</td>\n",
       "      <td>4.458786</td>\n",
       "      <td>2.288884</td>\n",
       "      <td>2.370949</td>\n",
       "      <td>0.869894</td>\n",
       "      <td>2.407945</td>\n",
       "      <td>2.484432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-1.500000e-07</td>\n",
       "      <td>2.600000e-07</td>\n",
       "      <td>7.100000e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.600000e-07</td>\n",
       "      <td>5.400000e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>6.500000e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lhx       lhy       lhz       rhx       rhy       rhz        hx  \\\n",
       "0  4.205590  4.694525  1.869073  4.921949  4.029522  1.889851  4.851381   \n",
       "1  3.667537  5.315720  1.828394  5.496964  5.049758  1.650158  4.452520   \n",
       "2  3.687988  2.772793  1.626460  6.565267  2.711560  1.630421  5.026713   \n",
       "3  4.726025  4.561223  1.902970  6.186168  4.496355  1.858916  4.920242   \n",
       "4  2.289227  4.712777  2.227426  2.993593  4.458786  2.288884  2.370949   \n",
       "\n",
       "         hy        hz        sx  ...      arhx          arhy          arhz  \\\n",
       "0  1.856576  2.092771  4.847641  ...  0.000940  3.774520e-03  5.399800e-04   \n",
       "1  1.847379  1.981042  4.470696  ...  0.001386  9.019000e-04  6.443000e-05   \n",
       "2  1.773879  1.677735  5.099942  ...  0.000232 -1.383200e-03  4.241600e-04   \n",
       "3  1.872385  2.126026  4.854091  ...  0.000949  7.901100e-04 -1.390000e-05   \n",
       "4  0.869894  2.407945  2.484432  ...  0.000001 -1.500000e-07  2.600000e-07   \n",
       "\n",
       "           alwx      alwy          alwz          arwx      arwy          arwz  \\\n",
       "0  1.797380e-03 -0.000401 -7.289700e-04  7.043100e-04  0.002726  4.028200e-04   \n",
       "1 -2.201000e-05 -0.000018 -9.400000e-07  3.954800e-04  0.000107  6.380000e-05   \n",
       "2 -5.700100e-04 -0.003331  2.262100e-04  8.658100e-04 -0.002652  3.404000e-04   \n",
       "3  1.242400e-04 -0.000161  4.246000e-05  4.017000e-05  0.000250  9.127000e-05   \n",
       "4  7.100000e-07  0.000003 -1.600000e-07  5.400000e-07 -0.000002  6.500000e-07   \n",
       "\n",
       "   Action  \n",
       "0       2  \n",
       "1       4  \n",
       "2       2  \n",
       "3       4  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    175\n",
       "0    152\n",
       "1    124\n",
       "4     71\n",
       "3     70\n",
       "Name: Action, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:42]\n",
    "y = data[[\"Action\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  7  1  0  1]\n",
      " [ 4 13 10  1  0]\n",
      " [ 1  5 27  0  2]\n",
      " [ 1  3  6 13  0]\n",
      " [ 2  2  6  2  4]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81        46\n",
      "           1       0.43      0.46      0.45        28\n",
      "           2       0.54      0.77      0.64        35\n",
      "           3       0.81      0.57      0.67        23\n",
      "           4       0.57      0.25      0.35        16\n",
      "\n",
      "    accuracy                           0.64       148\n",
      "   macro avg       0.64      0.57      0.58       148\n",
      "weighted avg       0.65      0.64      0.63       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8b2ddb240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO2dd7xcVbX4v+uWJDe5SUjvECAFSEgoIdIJVQQ1ggqoKE15qIgK+GyIEiygPP3BE/HRpBM6AiJFWiIEUkhIoySkkALppJB2y/r9cc41w2SvM+XOXCaT9c1nPplZs9s5Z+46++y111qiqjiO4zg7PhWf9AAcx3GcwuAK3XEcp0xwhe44jlMmuEJ3HMcpE1yhO47jlAmu0B3HccqEgih0EdkQ/z9KRJ4oRJuO4zhOblR90gOwqFs5L7hB/uUhPzbrnNswNyif+aP9gvLFt71vtvX5VauC8jee/61Z56Of/zooP/q1uqB84ou/M9uqf+TWoHzEn94MyqfPHmu29dZB3w/Kv7B+iVln5lWjgvIVf30jKD9u4VqzrdPaDQrKh2+RoHxDRVgO0L2+IShfWl1p1tlgTFvWStgHY2Cd3X+D8VXHhkazzvKq8ACscXWrN5uiktz8RraIfSw1jeG2Pqy063RuCNfZZFwz+6xAa8MHpso4xKRjOXPpXfaXWWLpnBDVXfdodn/FoBhLLrUi8qCIvCUid0tERxF5W0QGA4jIvSLyrSL07TiOkx+NDdm/SpRizND3B4YAS4GXgcNU9d8iciFwm4hcC3RS1ZuK0LfjOE5+aNLzxI5BMWboE1V1sao2AtOA/gCq+iwwA7ge+GaoooicLyKTRWTyzXfcW4ShOY7jGDQ2Zv8qUYoxQ9+S8r6hqQ8RqQD2BjYBnYHF6RVV9UbgRshtPctxHKe5aBnM0KUQwblEZIOq1orIKOBSVf1sLP8zMFlVbxORS4DBwJ3An4BDVDVsLQRe7PHl4MAOm3W1OY6FR347KF+2un1QPuwLG8y2Zj/WNiivMAxpAHuOWB2Uvzu5c1DeqLZdZcD+YaPs3KldgvL6Rvtha+QbvwnK3zv2IrPOwhUdg/IRXwgbP998vJ3Z1gvV4XO50TiX3S3LIzBga9hiOKu1PTexmqs0LuXqCvsPu1dD+DwP3mr+lJnZujoot3rpnLBEO7hxU1A+X2qC8gT7rknSY7thx2Zw/Zag/N3K1jn3b5m3LSMuwJffv7vZRsqti2dkrQxb9d23JI2iLbLLRUQGES2zjFTV9SIyDrgM+GVL9O84jpORMpihF0Shq2pt/P+LwIsp8gtTiu2dIr+4EP06juMUjAb7KWtHoWT3oTuO47QoJWzszBZX6I7jOLhRtKjs0XX/4MCe6d7drLPbuBuC8v4DPxeUj229d1AOMPLlS4PynsPPNOss+OJuQXnNmD8E5T2GnGa29bfakUH5SZN/GpQPO+Bcs63HuoQNqbuP/4tZZ5ddjwnK/9H+oKD80Ak/Mtt64PDrgvIPjOmEZSwFqDEMyW0TfsbzKsNWxqF1YfPbGtvpFMte2Tqh/zbGd3Orwq0NqLcH0L0+rHQ2G16UGxK8Pi2jsOXBCbDKaK9nfbhOkguONbY2hl7t0mC70J64bGyzjZRb5ryStTJsPfDQjP2JyInAtUR23ptV9aq073cDbgW6AauBM1V1u91/ueDBuRzHcSAyimb7yoCIVBL53HwG2Af4iojsk1bsGuAOVR0GjAHsWCBZ4grdcRwHIqNotq/MjATmquo8Vd0KjAVGp5XZB3gufv9C4PuccYXuOI4DOXmKpnq1x6/z01rrAyxK+bw4lqXyBvDF+P0pQHsRCa+PZokbRR3HcSCnfeipXu0GoTX29DX6S4E/i8jZwDhgCZAQazMzBVfoTV6jzW3HCnk79U/rzTpHGcbPBXMeD8qTQvHuduA5QfnSx39i1nn77MeC8mOGnh5u6+//bbZVd/9DQXmPvU4JypeMOdps651rlwXl/QacbNb5cP7TQfnr+4eNsr33s43Ff2gfNvD2NH+6Ynp3rjOeKTsZYV0BhjSGjYyW52F1ggev1ctHCc+6NYaeGGQYPzclmNvWVoY7sjxC2yZ4V1YYXyWFz7WMv2uNOpbhFaCTYeCtMwy8C6uLPP8s7LbFxUC/lM99iQIW/gdVXQqcCiAitcAXVdWOQ50FBT1DIiL4Mo7TTBI8/x2naKgWNCzuJGCgiOxONPM+A/hqagER6QqsjgMZ/pRox0uzaLbyFZH+IvKmiPwFeB2oEZHfiMgbIvKqiPSIy/1dRL4Rv/8vEbm7uX07juMUjALuclHVeuBC4GngTeB+VZ0lImNE5PNxsVHA2yLyDtADCAddyoFCzaYHE22/2T/+/KqqDidaF2pKZHE+cLmIHAFcAnwvvZFUQ8Otr71doKE5juNkQUN99q8sUNUnVXWQqu6pqr+JZZer6mPx+wdVdWBc5puqGo5wlgOFWnJZqKqvxu+3Ak15RacAxwOo6jIRuZxoe84pqrpdaMJUQ8PGq88pTY8nx3HKkxLORJQthVLoH6W8r9Nt7qf/iYcesy+wCuidqUEr3+ewL9h1xj4a9vy0jJ9JoXgfGho2WC774X1mnd2PDD+KPfDMAUH5ogsfNtvqdXT44enBdgcG5e/f+p7Z1p6ntArKHxo7xKzz8rDLgvLDZoTP2RP72Qbm1wzHx44Jfz+Wka9vXfgcT2pjt2V5kXZqDHeS5PVpGRK7GQY+gNeNsbXT8DW2jcXQwchdahkSk/Kz9jFmmusqbbVgHWUX4/g3VdiLAOsMA2/PeusEJLjwFoIycP1vsW2LIjKSyGtqf+AlEXlGVee3VP/OjkM+Mbwdp9mUQXCuFtmRIiKtgZuAc+OtOpcAt8a7YhzHcT55CmgU/aRo9gxdVRcAQ1M+16a8fxB4MP44PEX+GBDetO04jvNJUAYzdPcUdRzHAdQTXBSXz6/aPq/mJLqY+T4hHPZ2wqH/wxlbZm4nXwRMNIyfACNn/n472ZLj/ov954aX/hfsuxtqeOYdMXF7o+GCE3/GQYvmBMsvZhDPPdxpO3l7GoJtLTr5p4xeEXYym0A33nogfKkPeiV8/K8c8gc+s27idvJ1wIRhP9tO3qoCDpx+TbCt1w64nE4BA2gjsDwwrE4NsDFhMXBuq9CXjexaH660slJZKdsPoBNVpgF0jdF/lwbYEvquAZZWW4NuZEDd9t+9XwWrAuPqSSVb81iM3GqsYAbHG/NBVfh3YXnerqoU08axxTDAJm1Xs9paWxE2gHZubJZnfDI+Qy8eIWUOdvJmsGOYh5Q55K7MAVOZAzkpc8BU5kBQmSe1ZSlzIGdlDgSVOYSVOdjKHAgqcwgrc8hHmWMqcyCozMHezWIpc7CVo63MCSpzCCtzoGSVOdgKeIdX5lDSa+PZUrIK3XEcp0XxGbrjOE6Z4DN0x3GcMiFLl/5SpuD70ONgXeFFa8dxnFIlhwQXpUrJztDfeP63Qfn0T9uJja0EzlYM8yQ3/u79TwjKly94xqyz9uvhGOq99z0jKF+54FmzrboHrw3Ku+7zpaB8xdQ7zLYWjv51UN5j2FeDcoA1/w73/+EP/19Q3mnXY822ruh6WFDery5sMrMSHgN0rw8bEldU2W7hezSEf+YbjW66J4QksP6UuxnjAlhujG23hrC8VYIlcY3hLm8dfW3CsVQbyaBXVtnnv4NxAtYZRtGkY7GMr1aV96qr7cYKQQkr6mwplqdopYjcJCKzROQZEWkvIpNEZBSAiPxORJodKtJxHKdglIGnaLEU+kDgelUdAnxIlPz0bOAGETkeOBG4okh9O47j5E4ZLLkUS6HPV9Vp8fspQH9VnQXcCTxOFNNla3ql1HjoNz/wjyINzXEcJ0AZzNCLtYaeGqi9AaiJ3+9LNGPvEaqUGg99y8xnPR664zgtRxnschE1DCN5NyjSH3hCVYfGny8FaoHpwAVEaZmeAEaq6odWO6tHH5XzwCp3Cd+f5r/YLijf/ciPgnKwvT7rV9tWpo53/i0o33z5d4PyLe9uNNuq/X3YI3TrX8LGSt1o/xgrOrYOyhvX2wlS5jzXPigffGq4n4Zl9rm865U+4XEZ5bckeEp2MU6/lTwa4I3K8HHu3xA+L0nhe2uNyVlSMmbLYDitaruHVAAOqQvHr0/qxzJwWkmlk+pYsdXBNgpXGYdfn3AudzFiu1t9dFY71sqoZQ80O3Lrpgd/nbXOqfnSZSUZKbalEjp3Ba4CzlPVd4A/A2HN5DiO80lQBmvoBV9yCYTT3S7Ih6peV+h+HcdxmkWBVys+CUp2H7rjOE6LUsIz72xxhe44jgOu0IvJ0a+FDSA3VwY3yAAw/JVfBOXHDD09KLeSN4Mdptby+gSYbxg/24y5PijffY8TzbbuPeH2oHzUjD8H5YcMP9ds66+VYQPnsAm/M+sccu9JQflT9x0elB8x2fYT63DwH4LyDxJ+fZXG0+8KwyUyKbFzV8IehjXG3++GhHFVW+FjK20bWbUxts7Gn1+SUdY6TMuQuSmhrQZy9+7caJz/9gkeqRarqsImvNbGdWnfUGSTXxnscilZhe7svFjK3HGKiq+hO47jlAm+5OI4jlMmuEJ3HMcpE0rYpT9bSlahT3wxbLCbdoztj9RjyGlB+dK/h3NnLrrwYbOtbkO+HJQnhbxd+7Vw+FzL+Pn+vKfMturu+2NQ3mX3TwflK6bfY7a14ORwHLRue59q1lk/IWzIXXHB/wblnQaPNtu6omvYkGqFzwU7hK4VPndVQvhcNfzn1hlVeuZhG+uSED7XCu3b0zDyVSQs5W4wvE7N8LkJOqrCMLFanq1gh+PdYNgrkwysHY3wudaZXFxV3PC5mnANdxRKVqE7Oy9J8dAdp2iUwQy9KPuARKSdiPxDRN4QkZkicpaIvC0ig+Pv7xWRbxWjb8dxnLxo1OxfJUqxNnaeCCxV1eFxkK5HiYJy3SYiZwCdVPWm9EofC597/+NFGprjOE6AAsdyEZET44nsXBEJpk0TkdNEZHacDMheN82SYi25zACuEZGriSIvjgeeFZEvA9cDw0OVPhY+962XSvc26DhO+VHAXS4iUkmk644HFgOTROQxVZ2dUmYg8FPgMFVdIyLdm9tvURS6qr4jIgcCJwG/E5FngF8DewObgM5EB2lS/8itQfmA/VeZdf42ZWRQXnf/Q0F5r6PtB5TbH/5UuC0j1yfYIW8tr0/L8AlQffrF4bbGhI//X4dey9GXdQp+1/uYcB/WMQLU3fTXoLzzyeHf3G2Le5ptWRd6Y4Lxzcr32clYX08KnzuvMmzl3NPINWoZ+MD2SK1PWPffaLQ33xjXsEb7z7LWeNyvMJxiNlXYB5OPp2ijcZjWeUmalVnhe9U4lz3qi+zJWVjHopHAXFWdByAiY4kyt81OKfMtosxua6LudXlzOy3WGnpvYKOq3gVcAxwA/BB4E/gKcKuIFDnj686Fpcx3RCxl7jhFpb4h+1dm+gCLUj4vjmWpDAIGicjLIvKqiNixQLKkWEsu+wJ/EJFGoA74LnA7UVKL9SIyDrgM+GWR+nccx8mNHHa5iMj5wPkpohvjJeP/FAn1kPa5iij/8iigLzBeRIYmJf7JRLGWXJ4Gnk4T753yfXg9wXEc55Mih90rqfY+g8VAv5TPfYGlgTKvqmodMF9E3iZS8JOyHkgaLZWxyHEcp6TRxsasX1kwCRgoIruLSCvgDOCxtDKPAkcDiEhXoiWYec05BncschzHgYLuL1fVehG5kGilohK4VVVnicgYYLKqPhZ/d4KIzCZykP2Rqtq7PrKg4EmiC8Xe3UcGB3ZbVV+zzv4Twy7uPfY6JSh/sN2BZltWPPSu+3zJrLP4zIFBec2V4Rjmlhs/wL214R0oJ8wKxx3ff8hXzbZuqewdrjP5SrNO2/4nBOX/7BR24z9qymVmW/ePvDooX2qYxZNim1v7HNol1FlYGZ5RDa4LP6AuT5jmdDAmZ0lzNut45lWFa+1Rbz84dzDc5S078qqEOO3WbpY2CTphrdGeFRLA2hUDdtz3NsbJ7N5gJ4k+ftl9zTalf/TrM7NWhu0uu6skTfc+Q3ccx4Fsd6+UNK7QHcdxoKRd+rPFFbrjOA6URXCuZit0EdmgqrWFGIzjOM4nhs/Qi8f02WOD8olDw7HNAYYdEE6UvGTM0UH5+7e+Z7Z1wMjvBOUrpt5h1tl8ZdhPykrgnBTDvOHJcD+W8XPqLLutdw+9MCgftt/ZZp31N309KF/914lB+fADzjPb+kpN2Fg8eGu4fFJIACse+tJqOx56l8awkXFBVfgPeEBClmbLyNepwV5//cCIh97ZGFetYfgEqM/RFJdkYK4xFNiHCYbUTvXhOluMa5a0Kp2rgXd5ZZHjoZdBxqKC7UMXkb+IyOfj94+IyK3x+/NE5NcicpCITBeRNnF43VkiMrRQ/TuO4zSL+sbsXyVKIWfo44AjiDbP9wF6xfLDgbGqOklEHiMK0lUD3KWqMwvYv+M4Tv6UwRp6IT1FxwNHiMg+RBHFlolIL+AQ4JW4zBiicJIjgN+nN/CxeOh33FvAoTmO42SgDBJcFGyGrqpLRKQTUXKLcUQhck8DNqjq+rhYZ6AWqAbaAB+ltfGf+Ah1K+eV7llzHKfs0BJW1NnSbE/R1F0uInIbcEz86gI8CDyoqj+Mv38MGAvsDvRS1bC1Dpix++eCA9vr1WvMscwf9f2gfOPGVkH5nqfYx/7WA+F7XccOm8w6vY4NP/C8/Wi4//a1W8y2rBjmsx+tCY+rdrPZ1p6vhD1VFx75bbPOh+vC/ex1WvixdNZYe27wQnXboLzOiJa9S4J74Z5bw76ib7e2+99sNGd5Sq6psB+9exuJnQdutb0YZ7YOG/O2GOPqkRD2e3Bj+Pe3UNoYfeTu0Jj02G6Nec+6sIV7YVX4tw92YmuL2gb7upz6wT3N9txcf9Fns1aG7a97YqfwFB0PnKCqc0VkIdGMfDyAiHwDqFfVe+JsHq+IyDGq+nyBx+A4jpM7ZbDLpdkKPXUPuqreAtwSv68D2qV8dwdwR/y+AbDT5TiO47Q0Jbx7JVtKdh+64zhOS1KqgQpzwRW64zgOlPTulWwpWYX+hfVLgvJnjr3IrLP7+BuC8n4DTg7KHxo7xGzroFfCHqk9htlhahes3y0oHzbhd0F5t71PNduyEjif9PrPw30keH0+YRg/dxsXPl8A+/YLe9c+fU84EffBr4bDDQO8fdj/C8pXGB6JWyV6hZhtGD/bJvwtvl8R9lfcuz5slqtIMAta+U7fbmV7MVohd+ca4XO7iN3/Cm0dlFu9JyW8NhxlzeTNAOsMj9DVFeERJCWc3myMzQqf27bY+8RdoTtO4bGUueMUk3LYtugK3XEcB3yG7jiOUy6oEXhsR8IVuuM4DvgMvZjMvGpUUD7h54vNOsN2DbtXfjj/6aD85WF2HsyOQ74clK/597VmnZmjbwvKD7n3pKB8/YTrzbbqbvprUG7l+rTC3QLM+vlbQbll+ARYt+iFoHza8EuC8trBXzDbuqHbqKC8d8KMqM7wcLQ8FWsT/hhrGsPGTyt3Zs8ET80GI7jrpgTjY2vDljfIyGma1NbqyvCXlnNt0nmpML5KCp9bY3nXGnWqE3RkRyN8rhW9eEGrIqurHX8bemEUuogIURiBMjglzieNpcwdp5iUg1E072iLItJfRN4Ukb8A84g9REXk+yIyL36/p4j8W0Q6isjbIjI4lt8rIt8qxAE4juMUhMYcXiVKc8PnDiZy5z8EaEpWcQSwSkT6EMVCH6+qa4ELgdtE5Aygk6relN5YavjcW8ZNb+bQHMdxskfrNetXqdLcJZeFqvoqgIjUikh7oB9wD3AkkXJ/GEBVnxWRLwPXA8NDjaWGz91088Wle9Ycxyk7ymHBOO/wuSLSH3hCVYfGn28FphElr7gOOBc4CjhUVdeKSAXwElHo3JNUNXEK/t6IY4MD2+VA+x70+qMdgvKaSjuz4QHTrg7KJwz7WVA+aNAKs612+4VzZU+8r11QPmjXlWZbnU/uHpS/coP9q9tnj/DYOh4SHtfr94S9DgFqKsOWwf3e+J+gPCnX68RW4dCunRISTlrGz55GAKUpbex1d8sjsqthSUzKw2nRNSGw06Tw4dNaw/33brCPpYvRT71hd1ifkJ+1b3045O971bbXq2Ww7F4XHtemCnsRwGyrPvzbW19hB9w9/f27m214WXXyUVlf+S7/eKkkDT2FzFg0Drg0/n8qcDSwJV5uAfgh8CbwFeBWESluxtcssJT5joilzHdELGXuOMVEG7N/lSqF3Ac0nmi5ZZyqNojIIuAtABEZBHwTGKmq60VkHHAZ8MsC9u84jpM/JayosyVvha6qC9hmCEVV34Vtm3RV9YSU9+8Ae6d8vjjffh3HcYpBKc+8s6VkHYscx3FaksYEh7IdBVfojuM4AIaRekeiZBX6cQvXBuV3Lt3VrHPohB8F5b33OzMof2I/O4b3ITPDyag77XqsWWdxr/5B+RGTfxNua/Bos63bFvcMykdPCe++GX7AeXZbC3cJypNimFuu/C8Yu1lGzvy92db8YZcH5YsNs3jSLpM5rcJ2/D4Js6s5VeHtNH00vGtiVUL2Yiu2+XvV9v6CAUb+6JnV4XH1TEifbK0KWDtGkkIRv18VvgAdDJd8gA+qwg1a3r1J20asMVu7WTo1JmyLKgDlsORSyF0ujuM4OyzaKFm/skFETow95OeKyE8C318gIjNEZFrsUb9Pc4/BFbrjOA6F3bYoIpVETpSfAfYBvhJQ2Peo6r6quh/we+CPzT2Gkl1ycRzHaUkaExy68mAkMFdVm+JajQVGA7ObCqjqupTy7UheocqKZs/Q4yBdM+P3Z4vIn5vbpuM4TkuTy5JLatyp+HV+WnN9gEUpnxfHso8hIt8VkXeJZuh2wuQsydv1P2VA/YlDAIjI2cAIVb2wuQO7rP9XgwOrVfse1M8wPlmGoXUJxi/LLX1FQh3LmGcZ0pYntGV91c0w/s1LCDzdyojh3TvBkGgZrNYZp98aF8Dp08cE5X/dP2wsbZ/wSDu1OtzRMVbGYWCNEUP89LvD8fPvOPN5sy1rEje5crNZ50ubwg/C71eH5V86/gOzrTv/FTaWD9oaPi8bEhJOr6kKf2eFFwAY1C68WWH8lk5BebeEtj4wDMnW31Flgqo6e8ldzZ5eW+FGQuw6+bnE/uK4VZ9W1W/Gn79O5Fj5PaP8V+PyZ+Uw5O3IaYYuIleLyHdSPv8K+GJasd4i8pSIzBGR38fldos/dxWRChEZLyLhTA2O4zifAAU2ii4m8pxvoi+wNKH8WMDOEpMluS65jAVOT/l8GjAprcx+cZl9gdNFpJ+qLgSuBv4KXALMVtVn8huy4zhO4SmwQp8EDBSR3UWkFXAG8FhqAREZmPLxZGBOc48hJ4WuqlOB7iLSW0SGA2uA99KKPaeqa1V1M5EBYLe47s1Ae+ACoiBe25G6LvX6+rk5HorjOE7+qGb/ytyW1hPlgHiaKCjh/ao6S0TGiMjn42IXisgsEZkGXAw0a7kF8tvl8iDwJaAn0Yw9nS0p7xua+hCRtkSPHQC1wPr0iqnx0K01dMdxnGLQ2FDYXdyq+iTwZJrs8pT33y9oh+Sn0McCNwFdieKd20G1P87VwN3Awrj+Z5MKDzdiqM5IcCO0vNispL8dExzPPjDOTL86u38rUW4+bW004lgvNbwrB281m+KdVuF+ViQkA7YSOFca7tGW1yfYxs8LpoaNpc8OCXvDAvSrtH6ytvHNshf/71lh4+cPxtmbDZ4/JLxVeEMbI+g5sNHIxmwZH19+sqvZ1jG1a4LyWfVhb+B1Cde41vAIXWYYSwHqNob7Ob7r8qB8wqpwXH+AWuOSVRtTYOvvq1DslJ6iqjqLaOlkiaq+n00dETkKOAi4WlXvBraKyDm59u04jlMsGlWyfpUqeTkWqeq+Ke8XEIfRVdXbgNtSvkudhR+cIj81n34dx3GKhZawos4W9xR1HMeBrGO0lDKu0B3Hcchu90qpU7IKfYNhFOyeYMhcYxifGozQnpY3JNjeapuNtsDOhWl5uCW1tdH4yhqXZUQF2MUw9mxIsKBY4VCtY0wKeWt5fiYZP4+f9dugfO2wXwTlbdX+YfSWTeG2GsPJu58+9E/2uP751aB8/cn3mXXaGmFfu1SGLdlrGlqZbT1iGD+/ffDioPzvE/sF5QDLjU0EIxs2mnVWNob3QNy2vltQ/jn5yGzrTcLnf5Vh/ExKKl4IGgq8y+WToGQVurPzYilzxykmvobuOI5TJviSi+M4TplQytsRs8UVuuM4Dr7k8jFSw+gWor3u9WELSGVCDPiZrcOHY4V87Vtnu4bNNXJXWuOKxhYOemuF3E1qq5NhlHw3j3H1MM7ZbON8gW387Gl4N1q5PsEOeWt5fc4+4HL6GJ6qX5p+ZVB+/ohwPlmAIYbx8+2KLUF5Y4Lz898N4+fop75m1vn26FuC8v0a2wblbRNsc+9KOEzv7VPCxs9vHLAoKAf4/YzeQfkWCY8LoKvxu6gx/ixfqAqfe4CzB4THdsvc8LFYfRSKBt+2GBGnW3KcgmApc8cpJuUwQ89qn04oDrqIXCIiL4jIPcCM+KtKEbkpjiD2jIjUiEiViEwSkVFx3d+JyG8KfiSO4zjNoBxc/7PdeBmKg76CKG/ez1W1KfnpQOB6VR0CfAh8MQ4jeTZwg4gcD5wIXBHqJDV87lObPHyu4zgth+bwKlWyWnJR1aki0l1EegPd2BYHfaKqzk8pOl9Vp8XvpwD94/qzRORO4HHgEFUNelSkhs/9R4+vlPJ5cxynzCjlmXe25LKGHoqDnu4Glh4LvSbl875Es/YeOY7RcRyn6JTDGnouCj09DvrgbCuKyKlAF+BI4AkRGamqHybVWVodtrNaO1YA2hpz+k5G3OdJdghrdjViqK+osu2/liu95Ra/KqEt6zjbGW1Z5ytpXNb5AqhtDH85pU34R98nIUn0MVutixbeMZPkxm/tZrlx8h/MOpP2DdcZqOHdLBXY/TcYCbd/PPoOs87/Pf/joHzWqLApaZq2N9s6Zmv4R2vFEL9puu36/4N+S4LymXPsGObvVYcD31vhHZLc9e+cE+SEgr0AACAASURBVB7b17qHo3K/sdgeVyGwru2ORNbBC/KJgw4gIl2Bq4DzVPUd4M/AtbkO1HEcp5g0avavUiWnbYtpcdBfBF5M+byAOC56/PmalKqDUuTX5T5Mx3Gc4tJYBjN09xR1HMcB1BW64zhOeVAGKUVLV6FbhryGhJvovIqwBWZIY9hgmGQUfKsqbOXbo8E+ZdMrw67kXQkbkjTBhDGvMtx/G6NOl8aExL7GOXvfOF8ANcY5qzKMb3Oq7LZaa7gtK3mzFb8cbDd+y/AJcNCMsMH0vmHh5NVJHuADGsNj69dYE5QDTD7s6qD8wBcuDsqnHXuT2dYaw/Y9ZGtdUL6lPiG2+sI+QfnhNWvNOu/XdQzKN1mhIhrC4wKok/DfxT8/6BWUj2y13myrEPgM3XEcp0xI2Ki1w+AK3XEcB5+hO47jlA1lEGwx+33o6YhIfxGZWcjBOI7jfFI0Ilm/SpWSnaGvlbDFrH2Ce+7Q+rDFqMbwBOiUcEvuqeFTYyVvBti/Iex5WGOYz9clBB3e0zC+1hptLaiyLbzWOdvbOF8AbQzjZ1fjnPUxDJ8Ap999TFD+v2c9H5RbyZvBjmFueX2Cbfw8ffqYoPx/DgyXB1ihYePnNLETK+/TGDZM3nFc2Pj5qWrbKDnNMEqurggbGI286QB0N8IUz2gI9wEwqnfYp/CJZWFD5qKq8LgA1hvTyc6GfX0itgft/uY32VPC/kJZk3f4XOCLKZ+fFJFh8fupInJ5/P5KEfmmiJwiIv+SiF4i8o6I9CzsoTiO4+RPvUjWr1KlOeFzJ6V8HgccISIdiIzFh8Xyw4HxqvoI8AHwXaJ4ML9U1Q+aM3DHcZxCUg7hc7NS6Ko6FeguIr1FZDjbwuc2MZ4o8NbhwD+AWhFpC/RX1bfjMt8DfgpsUdV7Q/2kxkOfssHjoTuO03I05vAqVXIxijaFzz2dbeFzm5gEjACOIJqtTwW+RRQTvYk+ROeih4gE+1XVG1V1hKqOOLB2QA5DcxzHaR6Nkv0rG0TkRBF5W0TmishPAt+3FpH74u9fi/MyN4vmhM/9jxVKVbeKyCKipZgriZJgXBO/EJEq4G/AV4FvABc3fWcx0HBvnN3Kvj9WGPenasMoaIW1BVhj3Oq6J4QDtbz4NhhnuWeCJ4PlKbvcaGuA5Q4KvGWcM+t8gT02MxRwgoH3jjPDxs8fjLvIrPP0oX8Kyq0Ezkkhb60/QMv4ecmUsLEU4JkhPw/KG9rYiZU3S/j8W2GdF9bXmm0NMLxoFxEOq5uUVN0Kubum0v4tTVgSNn2dsmc4FO+L88KJqAEqjAtT2xg+X2sq896UlxWF3L0S51m+HjgeWAxMEpHHVHV2SrHzgDWqOkBEzgCu5uNL2zlTyPC544Flqroxft83/h/gZ0Rr6eOJlPk3RWTv5gzcKV8sZe44xaTAa+gjgbmqOi/O0DYWGJ1WZjRwe/z+QeBYkeZZXJsTPncBHw+X+wvgF/H7pbDtdqeqY1Lerwf2ynvEjuM4RaC+sJtX+gCLUj4vBj5llVHVehFZS5QIaGW+nRb3GcZxHGcHIZcZeuoGjvh1flpzodtD+uQ+mzI5UbKORY7jOC1JLq7/qQntDRYDqTn2+gJLjTKLYztjR2B19qPYnpJV6FaY3F4N9kPFZqOOdctL8qKrNb5L2rJkeXFW5/EoZxkfK4w+kn6MvY1zluT1mmt+xQ4JJ8a6ls8f8segvBoY9c+vBr/7+8n3hftIGK8V8tby+rQMnwAnzArnAd2w7y/MOo3GsmgvDXu9rsAOeftU67Dx88Qtm4Pyt8UO67vK+GF2MYy1YHsQ37A4bPw8pWqD2dYbDWHPzw+qwr/XpN9YIShw85OAgSKyO7AEOINoU0gqjwFnAROIdhA+r2qc4CwpWYXu7LxYytxxikkhFXq8Jn4h8DRQCdyqqrNEZAwwWVUfA24B7hSRuUQz8zOa268rdMdxHCAhTFR+7ak+CTyZJrs85f1m4MuF7NMVuuM4Dp7gwnEcp2wo5Rgt2VKyCr1jQ3hFq1e97RH4VqtwqM6PDDtqt3p71WxpRbhSt4T+1xmebFsMz7suCW1ZEd2WVIf72FAB/erC7fUyjvNt43wBbLI8ZY223jPGBTC1Mmyw29AmbOCbfsr97L41/Oc1+qmvBeU/Hn2H2b+V79MKeZvk9WkZP0+dcaVZ59IRPwvK92g0vDsTNEudsdI7pSp8jKN7hMPdAty4skdQnpTrtk2F4d1pjPlpsUPefvuEcHy+O/8V9katKbLGLYcEF81W6CJSqaoJDvFOS2Ap8x0RS5k7TjEp5aBb2ZLRsSgUC11ELhGRF0TkHmCGiPy3iFwUf/8nEXk+fn+siNwlIruJyBwR6SoiFSIyXkROKNpROY7j5MjOEm0xFAt9BVGsgp+r6j7E8dDj70cQhc+tZls89IVEgWf+ClwCzFbVZ9I7SvW+enqjh891HKflaJDsX6VKRoWeEAt9oqrOj4tNAQ4UkfbAFqKN8k3hdMfH7dxMFNzrAuBSo6//hM/9dFsPn+s4TstRDjP0bNfQm2Kh92RbLPSPmr5U1ToRWQCcA7wCTAeOBvYE3gSIE170javUAuubOXbHcZyCUQ6Wm2wVenos9MGBMuOIZt7nAjOAPwJTUlxZrwbuBhbGbX02qcPlhvvvBmP3Cdiu91aS5tfDmwwAGFBnjcsO/L3VeBSrNn4pKxLa2mgcphUS4IOEtjZUhL9LcqVubXw3yThn1vkC+NJWI+G2EXuhbaNt4P326FuC8v97/sdmncmHXR2UW8mbrfjlYLvxWztZAK6Z/Nug/K2Dvh+UT91qJ2nuYjzvVxge4/cvDydvBjinw4qgfPbKzmadVZW5/ZY6GYmoAe42drOcsc+ioHzqtOKmIW4sA5WebQq6TLHQIVpa6QVMUNVlwOZYhogcBRwEXK2qdwNbReSc5g7ecRynUOxMSy7psdBfBF5M+/45orhKTZ8Hpbx/CTg45fOpeY3WcRynSOz48/MSdixyHMdpSQqc4OITwRW64zgO5bGGXrIK3UqSnLR+NbcqbEwbVB825LRT24Qwszrc1m4NtvFxduXWoLyzcZp7JsR2n18ZDhVUY5g9OjfabVn5o+dW2WdzUF24vdZGSDrrfAHsLeHj72KEEehinEeA/RrDbvmzRoXjlAMc+MLFQfkdx90UlFvJm8GOYW658YNt/Nxr0rVB+fRh4eTVAKuMMBLD68LhFTY12OP659puQfkBRiJqgDWEQwxYv6SBCfHQtzSGwwI8PrNfUH5sPzuMQSHY8dV5CSt0x3GclqSUjZ3Z4grdcRwHX3JxHMcpG8ohvJ0rdMdxHMpjhi7NzEkaNRK5/Y8gcul/QlWHNrfNu3qfGRyYZeADe9vRFkPeLmHRzPL6bJVwuixzqTXmpCTV1mFagYFqEwx5G40Y1knbtKwxW56qSeuPpx0fjnv98pNdg/Ikb7dF1eE5SFUeP+MDq9cG5Qs315p1rGTUixPiwVtelFbc89OmjzHbmjj0v4PytRo+LzPb2HO2bkaKntpG+2R+9rd9gvLpPw8H05stdmz5pcZFG2TYxD8yfscAZy+5q9mbDn/Y/4ysf0V/WjC2JDc5+gzdcRyH8jCKZuX6n4qIPCoiU0RkloicHyhSKSI3xd8/IyI1IlIlIpNEZFTcxu9ExN5n5jiO08JoDv9KlZwVOnCuqh5ItMRykYh0Sft+IHC9qg4BPgS+qKr1wNnADSJyPHAicEV6w6nx0J/fOCePoTmO4+THThXLJYWLROSU+H0/IgWeynxVnRa/nwL0hyjAl4jcCTwOHKKq262UqeqNwI1gr6E7juMUg4YSnnlnS04KPV4yOY5IIW8UkReBdFe0VFe6BviYa9m+RLP2cHbaFCqNk7tHY9gjDmCFtg7K1xrJmzsYiaiTWGO0BdDWMCZZP5MNCUYeyzBltZVk4BzcGPb8s84XwGrjODsZ5yzpTFpJf4+pXWPWeaR+l6D8XQlf/2O22h6Rawxr9bS6cJjaAQmekk+1DvdjJW8GO+St5fVpGT4BRs78fVB+f4J3qYX1e11cbf+Y5o55MygfdtOxQfns8yebbXU3zksrDZ/LTeZWgcJQDrtccl1y6QisiZX5XqREUMyEiJwKdAGOBK4TkfBfrLPTYylzxykm5bDkkqtCfwqoEpHpwJXAq9lUEpGuwFXAear6DvBnIBzIwnEc5xOgHIyiOS25qOoW4DOBr/rH/68EhqaUvyalTGp89Oty6ddxHKfYlPLMO1t8H7rjOA6U9Mw7W3Y4hT5fwuE7AaqMC2J5PdYZ+SEBthrf2cFzodrwurX6SWrLyhFp5bRMYqGEDXnVQWlTP2F5vdF/kgfvoK1hl8RZxlr5IODYgxcHv7t9Sji0qnXuAYZsDSc8XV0RPgOLtrPzb+PELWGj7JQq+3dpXUsr5K3l9Qm28dPyLk0yllq/yy90WmbWGb8yvJ9himH8PP0S+7w8ck3Y+GzFVNm/Vdizt1DUF8Br/pNmh1PoTvljKXPHKSY7vjp3he44jgPsnNsWHcdxypKW2uUiIp1F5FkRmRP/3ylQZrc4xMq0OIzKBdm07QrdcRyHFt2H/hPgOVUdCDwXf07nfeBQVd0P+BTwExHpnanhgi+5NIXSVdWVzWlnSx7Gv82G56XlEVcvsNnoZ4txq6tNiIJveaRuskLeJvwyNlWE27JyrYId2tYiqS3LU3W9cY6tcMMArY18p+sMT8lHJvUzQwt/44BFQflN08PGUoAt9a2CcqsPy0sZ4G3DKD+6h53v8v7lvYJyK9/n8jz+KnM1lgJ8Z8SPg/KuH6SHZ9rGuvCpNEMEW4ZPgFOvCl+z31y+MCh/Xdtz6KZwR/uavWRPQ8ttXBwNjIrf3w68CHzsYqSFRmlNlpPvgs7QRSRp40bJYSnzHZFclXkpkxQn3tl5sZR5ochlhp4aSDB+hSLPWvRQ1fcB4v+7hwqJSL/YiXMRcLWqLs3UcE4KPRQ6V0Q2iMgYEXkNOCQu+j0ReV1EZsQhAhCR60Tk8vj9p0VknIj4ko/jOCWBqubyulFVR6S8bkxtS0T+JSIzA6/ROYxnkaoOAwYAZ4lIxhhYuT7cnauqq0WkBpgkIg8B7YCZqtqkrAFWquoBIvId4FLgm0TrRJNEZDxwHXCSqhGFx3Ecp4Up5C4XVT3O+k5ElolIL1V9X0R6AcsztLVURGYBRwAPJpXNdYZ8kYi8QRTDpSl0bgPwUFq5h+P/U8PnbgS+BTwL/FlV301vPPUx5sWPPB664zgtRwsaRR8DzorfnwX8Pb2AiPSNJ87Eu2AOA97O1HDWCj0tdO5wYCpR6NzNqppuKmwKodvAx58C9gVWAUFrbepjzKh26WHWHcdxikcLBue6CjheROYAx8efEZERInJzXGZv4LV4Av0ScI2qzsjUcC5LLnmHzo0HuxtwCbA/8KSIPKqqr1nla4xdFpsSYohbSXctI1ufBiNLLvBBVfjUJLmYW3duK7FwRcIPw6pjJam2zhfY5ywpsbJ1zvo2hN3o36+yAwmsqQrPG6zE1sur7Gv8+xnhnVs/6LfErPPIwnBi4+714f6TrvEqI1b4jYZLPMA5HVYE5f9c2y0ot5I3g71jy3Ljt3ayAPxl8tVB+XUH2OECdjF+5F3rw4NeXWmrmF9dviAs/82AoPz2n8w32yoEDS20Aqyqq4DtAsir6mSi5WlU9VlgWK5t57LkklfoXACJFtZvAS6NLbXnATeLGEFGHMdxWphyiIee9Qw9IXRubVq5/invJ7Ntv+VxKfIpFGbrqOM4TkHwaIuO4zhlQjnEcnGF7jiOQ7QPfUenZBX6h4ZbeE3CObeMWVZb6xIMNp0Mg93KBINdW2NxzTJkrksw8Fp12uR4jGCfsyTjn9Xehsqw8bODcb4AOhj9LDOMpSMbNpptbZG2QfnMOUFnOwAOrwnH0Z7REE4SvSbhXHYxjlMTzFGzV3YOyg8wklEvSYjHbiVwtmKYJ7nxW8bPi163wwU8vO8vgvI5rcN/S8dX24nAu25oH5Rf+7Ow8fP7v7SvcSHwGbrjOE6Z0FK7XIqJK3THcRw8wYXjOE7Z4EsujuM4ZUI5KHRpjmW3ULHPQzzQ62vBgSUZ/7YYX1mhZZNWzKykx1bc56T2NucRW91K0rzRaKuT4fUIdtxx63yBbUg1E27bTXFsq7BhbNbGcJLoto32SV5RFY7Q3JBwLNXGsYzqFY5hPmFJT7Mtyyi93DDwJvVv1fjyr+08BnPHvBmUT90aNvCuS3AdtK6x5cELcOqMK4PyWQf+ICh/hg5mW9Ymgp7Gb3ljwiaCbyy5q9mxsA/uPSprZfjq0hdLMva2z9Adx3Fo0QQXRSOX4FzbxUJP+e6/ReSi+P2fROT5+P2xInJXnB9vjoh0FZEKERkvIicU9lAcx3HyJ5d46KVKLrFczlXVA4ERRGF0Uze4jiOK1Uv8fa2IVAOHA+NVdSFwNfBXogBds1X1mfQOUsPn/mvj3DwOx3EcJz8a0axfpUouCj0UC72JKcCBItKeKHTuBCLFfgQwHkBVbwbaAxcQJb3YjtTwuce1DUdccxzHKQblMEPPag09LRb6RhF5Eba5s6lqXWwgPQd4BZgOHA3sCbwZt9EW6BtXqQXWJ/VphXwdXL8lKAdYLuEMtmsNo2CXenvNbIvRf5J3ZzujufaG8TOfhM+WIdUaL8CedVuD8tUVCSFvjXPWvS58kFb4VoDx2ikoP76rnajltvXh0LKWIa99UsJtY2hPLAsnbz5lTzsU7w2LwwbL2oS/ccuQbg15+s/tp9NhN20XdRWAKedPzqlvsEPeWl6fYBs/h0z5f0H51OF2KF7rF9O5MWxi31hhZKguEKU8886WbI2i2cRCH0c08z4XmAH8EZii225nVwN3AwuBm4DPNmfgTvliKXPHKSblEG0x2yWXbGKhjwd6ARNUdRmwOZYhIkcBBxFlrr4b2Coi5zR38I7jOIWiQRuzfpUqWc3QE2Kh908p8xxQnfJ5UMr7l0iZ1avqqXmM1XEcp2g0lvDaeLb4PnTHcRzKY8mlWZ6ixeS2PmcGB5Y0WivfomVgtTz4kvqxPCXBNvLk2kcSYT/JiATH0yBWiF6wj9M6Z8nXJfyIuqnCXvEbJB8F5S9UtQvK+yS4qvY08qAuMvKgtk74m9irakNQ/rSEQ8EC7L413N5Ao603Gu22LE6/pCYof+SacIhesK/ZATV2yNsn6sMGbisP6plv2KF47x8WNpi2Ms7/IbuGPXsB+r72fLM9Nwd1G5H1n+Q7Kya7p6hTPHJV5qWMpcwdp5iUwwzdFbrjOA6+hu44jlM2NOqO/5zrCt1xHIedy7HIcRynrCnVDSK5UJBdLiJSqVrY55V7e4fjoW9OcDG3Yoh3Mlz811XauyysXR5W8miAKuNcrjJiZXdMaMtK4LzSaCspSbO1yydpx441tg15tGV9V5uHf8aJey0Kyu+c08+s08X4Za43Ln/HPGLen3LCB2adu/8Vjq9uHf+iKvtadjcCv1uxxU+9yj4vv7p8QVB+9Ca7/7mtwnNA61iSdpKdNj28A+ZRIxH1rkZSbYBPLX242btO+nYemrUyXLx6ZknucsnKUzQUOldENojIGBF5DThMRB6O5aNFZJOItBKRNiIyT0SqRGRSHBMGEfmdiPymWAflOI6TKztNcC6i0LmrRaQGmCQiDwHtgJmqermIVAG3x2WPAGYSufpXAa+par2InA08GMdNPxH4VCEPxHEcpzmUskt/tmQbyyUUOrcBeAhAVeuBuSKyNzCSKDDXkXw8fO4s4E7gcaIbxHYhAFPjoT/n8dAdx2lBymGGnlGhp4XOHQ5MJQqduzlt3Xw8UbyXOuBfRMktDieKwtjEvsCHQI9QX6nx0I/1eOiO47Qg5ZDgIpsll2xC50KkuO8A7lDVFXFGo57ALAARORXoQjRzf0JERqrqh+bAjHOWkCOaVsYTkxWru6cRDxpgbUXYyT7pUloPbK2NL5KsyGqMuY3RVj4WGqstsA2Z3Y1ztt44XwAbjItmGX5XJVzkW+aGjXxf6267hf/zg3Dc887GBahNSFL9gWGUvtMwfAKcsU/YkPv4zPCxDAqHrweglbEsYP2WfnP5QrOtX/0mPGm69mfzzToDjDAGVgzzVQkx9y3j5xeMRNSPD73MbKsQtNTMW0Q6A/cRBTdcAJymqtvFWxCRXYGbiVZFFDhJVRcktZ3Nkks2oXMBXiOaeTfNyKcD01VVRaQrcBVwnqq+A/wZuDaLvh3HcVqERtWsX83kJ8BzqjoQeC7+HOIO4A+q2rSUbWeEick4Q08InVubVm4T0Drl8/kp71cCqeF0r8vUr+M4TkvSgmvjo4FR8fvbgReBH6cWEJF9gCpVfTYeWziSWxruWOQ4jkOL7nLpoarvA6jq+yLSPVBmEPBhvB18dyK75E8y+fu4QnccxyG34FyxP875KaIbVfXGlO//RWRDTOfnWXZRRbRLcH/gPaI197OBWxLHVapbcO7qHY6HnhSrun1j+Oa1sDp839olwbuyc2PY+PdetW3k2bMunMC6zjBVLDbicQP0MIyP1YZZdnml3VaNYeRrmzAjWWB4BHaqD/ffyTj3AEurwm1ttDw1E+Ygm4063evtSn1bbQzKJxpxx5O8XpOSLlv0qg8bDAf3WxmUP/9+2IgLttFr/1Zrg/JFG8Px4wHeM67xWb8MTRgjHvhlxmXcj3FM36Xmd0sW7RKWN7YJyj8389dmW9Vd92i252a7tv2zVoYfbVyQd38i8jYwKp6d9wJeVNXBaWUOBq5S1VHx568DB6vqd5PaznYfuuM4TlnTgkbRx4Cz4vdnAX8PlJkEdBKRpozpxwCzMzXsCt1xHIcWdSy6CjheROYAx8efEZERInJzPJYG4FLgORGZQbQz+aZMDfsauuM4DtDYQkZRVV0FHBuQTwa+mfL5WWBYLm27Qnccx6E8wue6QnccxyG/pO0lRy7rRp/kCzi/mOVLuU6pjsuPpTTHtbMfy8782pGMoudnLtKs8qVcp1THlU+dUh1XPnVKdVz51CnVceVbZ6dkR1LojuM4TgKu0B3HccqEHUmh35i5SLPKl3KdUh1XPnVKdVz51CnVceVTp1THlW+dnZKSdf13HMdxcmNHmqE7juM4CbhCdxzHKRN2eoUuInbuNMdxnB2IklboInJe2udKEfllQvkGEblKZFtCThF5PUM3c0XkD3GGkGzHdaWIVKV87iAif8tQZ7sEkiJiJqIUkYdE5GQRyfoahY4hTvKdVOc5ETkpTZZohMp1bCJyXEB2Vqhs/N27InJBmuyJDH1MFpHvikinbMYU19kuTqyIDA6VTfn+FhHZL032q4Ty14jIkGzHlFIvp99Yrr+v+PvOeYwrp2sZf5/T9cznWjoRJa3QgWNF5EkR6SUiQ4nymYaDWEfMIjqmZ1J+rJniFg8D3gFuFpFXReR8EemQoU4V8JqIDBORE4hCXU7JUGe+iNwrIm1TZE8mlL8B+CowJ75J7ZWhfYD7ReTHElEjIv8L/C5Dnd2BH6fdKEdkqJPr2C4XkRtEpJ2I9BCRx4HPJZSvA44Wkb+JSKtY1idDH2cAvYFJIjJWRD6demM3GC8ipzV9EJFLgEcy1Pk0cJuIfCNF9vmE8m8BN4rIayJygYh0zNB+E7n+xnL9fRG3/4CInJTFuWoi12sJuV/PfK6lA6Xv+g+cDqwkytpxWIayr8f/n0ak3A9skmXZ15HAEuAjolx/AxLKHgdsApYmlUspPxX4DtEf5Z5NsizqdQQuABYBrwDnANVG2XZECbgnADOBnwIVmc4ZkfL4C/B43F9W5yzbsRHdVC8F5sSvr2R5Hf+bKPn4bjmMqYJIwS6Jx3UF0Nko2ys+5geIkpv/H1CbxfnqENe7Pj532VzHwURhUhcC9wBHZ1En699YPr+v+LocD9wLvAv8FhiURZ2sr2Vzrmcu19Jf0aukZ+giMhD4PvAQsAD4etoMZLsqAKp6P5FS/xuwR4Y+KkXk8yLyCHAt8D9xnccxZjgiciRwHTAGeAn4s4j0znA4qqp/AS4CHheRz5EhHpCIdCFKO/VNoj/Ya4EDgGeNKnVECqAGaAPMV80YE1RUtV5Vv0N0nv8N2Clr8htbJ+BTREpjC7BbhhlX03X8PfAz4GmgbxZjGkZ0/f4QH8uXgHXA86HyGuV1fAo4BOgP3KGZk/GKqq5T1c8BK4iuf+KsWyI7zV7xayXwBnCxiIxNqHMk0TkdQ5REONNvLOffl0Y8q6pfIbqOZwETReQlETnEqJbrtYQ8rmeu19KJ+aTvKEkvosfVY3XbzOASYFZC+QPTPncAvpGhj3lEefoODXx3nVFnIrB3yudTgLcy9DM15X1PohnhxoTyDxNlKPkp0Cvtu8lGnTeIFEB13MffgQczjOu/0s8hcGuGOjmNjWhJ69z4fQ3RzfCVhPY/l/Z5V+DyDGOaAjxHtBTUOn28Rp1ngTuAXYCh8XW9JkM/V6R9/izwfEL5PwJziWb/I9O+ezuh3kRgn5TPpyb9xtJ+X70y/b7icl2IJkyTgX/EfVQRLbnNN+rkdC2N67lb0vXM51r6K3qVtGORiHRQ1XVpsoGqOiehzqFEs63/GJRU9Y6E8rWaeVa2XR2iR8HUfrqq6kUJdXoDo1LqtAIOUdXtAt3H5U8DnlLVdSJyGdHs99eqahp5RWSERkHyU2VfV9U7E+pcSfTH/4qqfmSVS6tztKq+kE3ZuPyuqvpemuxIVR2XUKcP0R9+6nVMKr+Hqs7LdkxxnS+o6qMpn6uAn6rqlQl1zgXGJ/0GA+XHqup2iU1FpKOqBpOBikilpmV4F5EuGiVHCJXvpXEm+ZRjOTTDOXsHuBP4m6ouTvvux6p6daBOPtfyTqLf2HhVfcsql1I+52vpRJS0QofcFHT8w9kTmAY0bCueqGi7Ad8K9HFuQp2ngLVEM4nUfv6YYx1U9ynlhgAAB+RJREFU9X+M8tNVdZiIHE5k2LwG+JmqfiqhjzHAeHJTzucChxMtO6yP649T1VCew6Y644n/QIGXVXV9Fv1kraBF5Coiw9hsPn5+TeOjiLQGvsj213FMQp2clHNcZwzR+dqN6Fo2na83jPI5KbOUejkdT57HL5qjAhCRO4iOOevjEZFjiM7ZEUTLmdOIztm1Rvl3iTZANJ3bjLk0nYiSVui5KmgReZPoMTXrgxKRV4h+OOmK9qGEOjNVdWi2feRTR0Smqur+IvI7YIaq3tMkS6iTs3JOqduTyO5wKdBJVc3dRCKyB9v+QA8mWksdr6o/NMpfTWTczkpBS5QVfZiqbsk07pQ6Od0w4zo5Kee0ujVEE4FLgT6qGvRnyFWZ5Xs8eR7/oHj8/fn4TeCYhDr5Hk8lcBBwNJEhfZOqBndHxTenT8V9HEZke3hDVU9J6sMpfYWek4IWkQeAi1IfPbOoM01V98tc8mN1bgT+V1VnFKuORPt0lxDtdDiQyNg5UVWHZ1E3F+V8M7APsIxIof2baAdCfYY+egFHEf3RHQ28p6onGmVzUtAi8k/gy7ksheVzk02pm5VyjsteRqRkaomMwf8mupmZv7lclFlKnVwnAPlMMt4A/sr2N4HELbi5Ho+IPEe0A2sC8W9MVZcnlK+K2z+K6ObRBZiuqv+V3ZHtvJR6CrqZRMa9RAUt0V5YJdqjPltEJhLNGgFIelQHnhCRk1Q1055dJMq+rUTn7RwRmRf3I1E3ul1C13zqxJwGnEhkpPswVqA/yjC+dOX8JaJtdkl0ASqBD4HVwMoslPm7RLs17iEyKH9Pk3fTzCMy1CYqdIn2zSuwEZgWK4LU62gunQGviMi+Od5k05XzpUTnLYlTgXoiI+JLwKuqujmhj3RldlCSMksh1+PJ+fiBelW9IYfy+R7PdKJJyVCip4gPRWSCqm4yyq8DZhAZlG+y7AbO9pTkDD1NQe9HZPE3FbSIHJXUnqq+FOhjPZFSrYn/30K07a9J0W7nXCQiu2XoZ2Eh6uSLRFsvexMtbbxE9CiclXFJRPYmcpr5IVCpqua2MhH5PtHMqR/RTqSmvt5NK9ekoPsAw4l2LpgKWjJ4HKrq7YGxpN4wBxLdPLK5YSKRF3HWyjmlXnui4z+c6Ma7TFUPN8r+iUiZbQFeJlpPN5VZrseTz/HLNqe7i4DlRM5UqddldcKx53Q8aXVriXwVLgV6qmpro9xoonM7EthK5OMwTlWfy9THzk6pKvScFXSe/QgwRVUPKER7pUKOyvmzRMsmRxLtMZ5AtIRwaxb9pP6B9k1fqshHQedKc2+YuSjnuPxQovN1FNH2vkVE5+vyDP1kq8xyOp48JxnziW4Cof3jqqqJvhtxG1kdT1z2QqJzdiCRY1WTkThxT7lEHsifAX4AdFfVmkzj2tkpySWXXBV2PNsO3ZnM2Xbcj4rIBBE5SFUn5THUkiKgnJ8n8xLCZ4j+wK5V1aVZ9CHAzUSPz7VEN4DLQ/3kqrBTZptBQrNNVV0oUUyZ6XmsIQeVc4ZqVxOdr+uASapal6GP7xHdLJqU2a0Z+si4Y6iZ5VHV3eNzdoiqvpxL3YByznQ8ED0F/5Fo8pS4nBf38RDRk/ncuO1vEHmYOhko1Rl6Xgo6z75mE7llLyBy+c/4qF6qiMj1bJv9ZFTOzehnHnBwprXTXBV0ymzzi0TLbIvSypuzbRG5m2gP+XtWmUCdf7Bt+2VG5ZwPItK0Lp+tMkufPTedv6bf5R7NKZ9Wd4KqWh6hVp0fEZ2zjMcjGYJ/hZZ24hvNYURbbxu2r+UkUZIKvSWxHlkLubZdijTnphnfOG7L9FSTr4KWKFDYaURG2rFE3q7LMvT1PNHOiIlEN+amPpIM4lmTcHNKWqvO68khpX5nonXxNk2ypKfXPMpfQWSwfFgzKII8lXNoaafps3mzyedG40Ts9Aq9HGjJJ5q4v9nAIKJH7oxPNfko6LjeMKL9618EFqvqdqFbU8peTGTge48UBWIYxPNRzvnenHJ+cojrfZPILb8v0V7vg4lmrZZncU7l4zrriXas1AObSd4QkJdyTqmf9c0mlxuN83FKcg3dyQ1N2GdeJD6TS2FVvQK4IkVBvyQiiQo6ZjnwAbCKzAHD2gPnkd1N47Px/0HlbBzDQviPEfX/suwHorgqs+KttLk8OXyf6InjVVU9OjYQXlHA8qhq+5CiNcru3vQ+2zop5YM3G8C62VxMfKMRkcQbjfNxXKE7OdOM5aisFLSIfJtI8XcDHgS+pRncv3O5aTRDOedzc3qCyHD4sSeHLNisqptFBBFprapvSXLyjVzL56No86pDjjebXG40zsdxhe4UnTwU9G7AD1R1Wh7dZT2rb8aTQy795PLkkMpiEdkFeBR4VkTWEMVFL1R5yGNWn2ednG42ed40HFyhOy1DTgpaVX+Sawf5zOpTyPomkGs/+d40dFvckl+JyAtEMdefKlT5mJxn9XnWyfVmk89Nw8EVutMC5KOg8yDnWX2eN4F8nx5ysQd8jFz9MnIon8+sPuc6edxs8rlpOPguF2cnRqIwvWPzXNrJto/0m8Z9OTw5tBgSeWd3JIrBv7VYdbJs9xEiL9QfAMcAa4hSG56UWNFxhe44xaQlbhrlTLFuGuWKK3THcZwyoaSTRDuO4zjZ4wrdcRynTHCF7jiOUya4QnccxykTXKE7juOUCf8faH6pswfm+IIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "corr = X.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if corr.iloc[i,j] >= 0.95:\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "selected_columns = X.columns[columns]\n",
    "X_new = X[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lhx', 'lhy', 'lhz', 'rhx', 'rhy', 'rhz', 'hx', 'hy', 'sy', 'vlhx',\n",
       "       'vlhy', 'vlhz', 'vrhx', 'vrhy', 'vrhz', 'vlwx', 'vlwy', 'vlwz', 'vrwx',\n",
       "       'vrwy', 'vrwz', 'alhx', 'alhy', 'alhz', 'arhx', 'arhy', 'arhz', 'alwx',\n",
       "       'alwy', 'alwz', 'arwx', 'arwy', 'arwz'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  2  2  0  0]\n",
      " [ 5 15  5  3  2]\n",
      " [ 4  7 32  1  2]\n",
      " [ 1  4  3 10  0]\n",
      " [ 2  4  3  5  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80        36\n",
      "           1       0.47      0.50      0.48        30\n",
      "           2       0.71      0.70      0.70        46\n",
      "           3       0.53      0.56      0.54        18\n",
      "           4       0.50      0.22      0.31        18\n",
      "\n",
      "    accuracy                           0.63       148\n",
      "   macro avg       0.59      0.57      0.57       148\n",
      "weighted avg       0.62      0.63      0.61       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    175\n",
       "0    152\n",
       "1    124\n",
       "4     71\n",
       "3     70\n",
       "Name: Action, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    129\n",
       "0    116\n",
       "1     94\n",
       "4     53\n",
       "3     52\n",
       "Name: Action, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['Action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  5  0  0  0]\n",
      " [ 9 13  1  3  4]\n",
      " [ 4 11 28  1  2]\n",
      " [ 0  7  1  9  1]\n",
      " [ 4  6  2  5  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74        36\n",
      "           1       0.31      0.43      0.36        30\n",
      "           2       0.88      0.61      0.72        46\n",
      "           3       0.50      0.50      0.50        18\n",
      "           4       0.12      0.06      0.08        18\n",
      "\n",
      "    accuracy                           0.55       148\n",
      "   macro avg       0.49      0.49      0.48       148\n",
      "weighted avg       0.57      0.55      0.55       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = neigh.predict(X_test)\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data['Action'] == 4]\n",
    "df2 = data.loc[data['Action'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.concat([data, df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lhx</th>\n",
       "      <th>lhy</th>\n",
       "      <th>lhz</th>\n",
       "      <th>rhx</th>\n",
       "      <th>rhy</th>\n",
       "      <th>rhz</th>\n",
       "      <th>hx</th>\n",
       "      <th>hy</th>\n",
       "      <th>hz</th>\n",
       "      <th>sx</th>\n",
       "      <th>...</th>\n",
       "      <th>arhx</th>\n",
       "      <th>arhy</th>\n",
       "      <th>arhz</th>\n",
       "      <th>alwx</th>\n",
       "      <th>alwy</th>\n",
       "      <th>alwz</th>\n",
       "      <th>arwx</th>\n",
       "      <th>arwy</th>\n",
       "      <th>arwz</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.205590</td>\n",
       "      <td>4.694525</td>\n",
       "      <td>1.869073</td>\n",
       "      <td>4.921949</td>\n",
       "      <td>4.029522</td>\n",
       "      <td>1.889851</td>\n",
       "      <td>4.851381</td>\n",
       "      <td>1.856576</td>\n",
       "      <td>2.092771</td>\n",
       "      <td>4.847641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>3.774520e-03</td>\n",
       "      <td>5.399800e-04</td>\n",
       "      <td>1.797380e-03</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-7.289700e-04</td>\n",
       "      <td>7.043100e-04</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>4.028200e-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.667537</td>\n",
       "      <td>5.315720</td>\n",
       "      <td>1.828394</td>\n",
       "      <td>5.496964</td>\n",
       "      <td>5.049758</td>\n",
       "      <td>1.650158</td>\n",
       "      <td>4.452520</td>\n",
       "      <td>1.847379</td>\n",
       "      <td>1.981042</td>\n",
       "      <td>4.470696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>9.019000e-04</td>\n",
       "      <td>6.443000e-05</td>\n",
       "      <td>-2.201000e-05</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-9.400000e-07</td>\n",
       "      <td>3.954800e-04</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>6.380000e-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.687988</td>\n",
       "      <td>2.772793</td>\n",
       "      <td>1.626460</td>\n",
       "      <td>6.565267</td>\n",
       "      <td>2.711560</td>\n",
       "      <td>1.630421</td>\n",
       "      <td>5.026713</td>\n",
       "      <td>1.773879</td>\n",
       "      <td>1.677735</td>\n",
       "      <td>5.099942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-1.383200e-03</td>\n",
       "      <td>4.241600e-04</td>\n",
       "      <td>-5.700100e-04</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>2.262100e-04</td>\n",
       "      <td>8.658100e-04</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>3.404000e-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.726025</td>\n",
       "      <td>4.561223</td>\n",
       "      <td>1.902970</td>\n",
       "      <td>6.186168</td>\n",
       "      <td>4.496355</td>\n",
       "      <td>1.858916</td>\n",
       "      <td>4.920242</td>\n",
       "      <td>1.872385</td>\n",
       "      <td>2.126026</td>\n",
       "      <td>4.854091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>7.901100e-04</td>\n",
       "      <td>-1.390000e-05</td>\n",
       "      <td>1.242400e-04</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>4.246000e-05</td>\n",
       "      <td>4.017000e-05</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>9.127000e-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.289227</td>\n",
       "      <td>4.712777</td>\n",
       "      <td>2.227426</td>\n",
       "      <td>2.993593</td>\n",
       "      <td>4.458786</td>\n",
       "      <td>2.288884</td>\n",
       "      <td>2.370949</td>\n",
       "      <td>0.869894</td>\n",
       "      <td>2.407945</td>\n",
       "      <td>2.484432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-1.500000e-07</td>\n",
       "      <td>2.600000e-07</td>\n",
       "      <td>7.100000e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.600000e-07</td>\n",
       "      <td>5.400000e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>6.500000e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.109002</td>\n",
       "      <td>3.927355</td>\n",
       "      <td>1.501798</td>\n",
       "      <td>6.920993</td>\n",
       "      <td>3.501003</td>\n",
       "      <td>1.423287</td>\n",
       "      <td>5.430639</td>\n",
       "      <td>1.736059</td>\n",
       "      <td>1.697598</td>\n",
       "      <td>5.544961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>5.679420e-03</td>\n",
       "      <td>3.864300e-04</td>\n",
       "      <td>-1.660200e-03</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>-5.743000e-05</td>\n",
       "      <td>6.865130e-03</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>-2.456900e-04</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.668501</td>\n",
       "      <td>4.950205</td>\n",
       "      <td>2.279571</td>\n",
       "      <td>4.796742</td>\n",
       "      <td>5.128264</td>\n",
       "      <td>2.298723</td>\n",
       "      <td>4.656317</td>\n",
       "      <td>4.701049</td>\n",
       "      <td>2.555991</td>\n",
       "      <td>4.683853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>2.278100e-04</td>\n",
       "      <td>-2.087300e-04</td>\n",
       "      <td>2.952700e-04</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>3.555000e-05</td>\n",
       "      <td>-1.612900e-04</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-2.520000e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.272500</td>\n",
       "      <td>5.525830</td>\n",
       "      <td>2.119054</td>\n",
       "      <td>3.766633</td>\n",
       "      <td>5.583711</td>\n",
       "      <td>2.266399</td>\n",
       "      <td>2.786795</td>\n",
       "      <td>1.327088</td>\n",
       "      <td>2.212436</td>\n",
       "      <td>2.523509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>5.166000e-05</td>\n",
       "      <td>4.850000e-05</td>\n",
       "      <td>-7.413000e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>6.573000e-05</td>\n",
       "      <td>-7.888000e-05</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>3.841000e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.330683</td>\n",
       "      <td>5.037382</td>\n",
       "      <td>1.891318</td>\n",
       "      <td>5.021062</td>\n",
       "      <td>5.152056</td>\n",
       "      <td>1.907732</td>\n",
       "      <td>4.879743</td>\n",
       "      <td>1.844396</td>\n",
       "      <td>2.115820</td>\n",
       "      <td>4.854716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>2.432900e-04</td>\n",
       "      <td>1.842100e-04</td>\n",
       "      <td>6.456500e-04</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-2.107000e-05</td>\n",
       "      <td>2.957500e-04</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>1.021800e-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.421911</td>\n",
       "      <td>3.245796</td>\n",
       "      <td>1.353590</td>\n",
       "      <td>5.741972</td>\n",
       "      <td>3.886645</td>\n",
       "      <td>1.492309</td>\n",
       "      <td>5.062042</td>\n",
       "      <td>1.622844</td>\n",
       "      <td>1.738860</td>\n",
       "      <td>5.003149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>2.066430e-03</td>\n",
       "      <td>2.296200e-04</td>\n",
       "      <td>-1.073970e-03</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-2.757300e-04</td>\n",
       "      <td>4.522600e-04</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>4.323600e-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.920042</td>\n",
       "      <td>3.978703</td>\n",
       "      <td>2.211195</td>\n",
       "      <td>2.968426</td>\n",
       "      <td>0.834077</td>\n",
       "      <td>2.202471</td>\n",
       "      <td>2.259430</td>\n",
       "      <td>0.845343</td>\n",
       "      <td>2.406115</td>\n",
       "      <td>2.445755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-3.771000e-05</td>\n",
       "      <td>9.450000e-06</td>\n",
       "      <td>-9.300000e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.770000e-06</td>\n",
       "      <td>6.300000e-06</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>4.950000e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.026071</td>\n",
       "      <td>4.238918</td>\n",
       "      <td>1.941478</td>\n",
       "      <td>6.304251</td>\n",
       "      <td>4.498418</td>\n",
       "      <td>1.842593</td>\n",
       "      <td>4.893420</td>\n",
       "      <td>1.859839</td>\n",
       "      <td>2.126839</td>\n",
       "      <td>4.859129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>3.359630e-03</td>\n",
       "      <td>7.484200e-04</td>\n",
       "      <td>2.095370e-03</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>1.271600e-04</td>\n",
       "      <td>-6.258680e-03</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>8.990200e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.199439</td>\n",
       "      <td>4.980598</td>\n",
       "      <td>2.003031</td>\n",
       "      <td>2.549979</td>\n",
       "      <td>4.901636</td>\n",
       "      <td>2.009590</td>\n",
       "      <td>2.720113</td>\n",
       "      <td>1.314647</td>\n",
       "      <td>2.221931</td>\n",
       "      <td>2.663610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>-1.818700e-04</td>\n",
       "      <td>-7.426000e-05</td>\n",
       "      <td>2.940500e-04</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-4.416000e-05</td>\n",
       "      <td>-2.099800e-04</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-2.683000e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.780814</td>\n",
       "      <td>4.560586</td>\n",
       "      <td>1.483252</td>\n",
       "      <td>4.966421</td>\n",
       "      <td>4.546110</td>\n",
       "      <td>1.496978</td>\n",
       "      <td>4.976627</td>\n",
       "      <td>1.656472</td>\n",
       "      <td>1.769066</td>\n",
       "      <td>5.035172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>-2.502310e-03</td>\n",
       "      <td>-4.183500e-04</td>\n",
       "      <td>-9.879400e-04</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>-8.126000e-05</td>\n",
       "      <td>2.152710e-03</td>\n",
       "      <td>-0.002860</td>\n",
       "      <td>-4.725400e-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.556494</td>\n",
       "      <td>5.099709</td>\n",
       "      <td>2.419096</td>\n",
       "      <td>4.669863</td>\n",
       "      <td>5.024026</td>\n",
       "      <td>2.343937</td>\n",
       "      <td>4.677213</td>\n",
       "      <td>4.693687</td>\n",
       "      <td>2.613214</td>\n",
       "      <td>4.683428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>7.982000e-05</td>\n",
       "      <td>2.511400e-04</td>\n",
       "      <td>-6.833900e-04</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-3.342100e-04</td>\n",
       "      <td>-1.105830e-03</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>-7.919800e-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.265414</td>\n",
       "      <td>3.057349</td>\n",
       "      <td>1.468588</td>\n",
       "      <td>4.556957</td>\n",
       "      <td>3.596444</td>\n",
       "      <td>1.530195</td>\n",
       "      <td>5.581937</td>\n",
       "      <td>1.251014</td>\n",
       "      <td>1.763594</td>\n",
       "      <td>5.482471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002868</td>\n",
       "      <td>1.979050e-03</td>\n",
       "      <td>8.914700e-04</td>\n",
       "      <td>2.652100e-04</td>\n",
       "      <td>-0.000865</td>\n",
       "      <td>-2.095200e-04</td>\n",
       "      <td>3.827700e-04</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>2.538800e-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.853124</td>\n",
       "      <td>4.676322</td>\n",
       "      <td>1.968942</td>\n",
       "      <td>3.509686</td>\n",
       "      <td>4.109926</td>\n",
       "      <td>1.983233</td>\n",
       "      <td>2.848704</td>\n",
       "      <td>1.303667</td>\n",
       "      <td>2.227088</td>\n",
       "      <td>2.637406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>6.521000e-05</td>\n",
       "      <td>4.460000e-06</td>\n",
       "      <td>1.880600e-04</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-3.450000e-05</td>\n",
       "      <td>-9.043000e-05</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-3.896000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.660271</td>\n",
       "      <td>5.251965</td>\n",
       "      <td>1.793846</td>\n",
       "      <td>5.698182</td>\n",
       "      <td>1.737274</td>\n",
       "      <td>1.751455</td>\n",
       "      <td>4.181806</td>\n",
       "      <td>1.805099</td>\n",
       "      <td>1.966767</td>\n",
       "      <td>4.436745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-5.050850e-03</td>\n",
       "      <td>-4.702400e-04</td>\n",
       "      <td>-2.896000e-05</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>-6.310000e-06</td>\n",
       "      <td>-1.048500e-04</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>4.050000e-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.663677</td>\n",
       "      <td>5.086694</td>\n",
       "      <td>2.248109</td>\n",
       "      <td>4.663788</td>\n",
       "      <td>5.086501</td>\n",
       "      <td>2.247355</td>\n",
       "      <td>4.661151</td>\n",
       "      <td>4.695288</td>\n",
       "      <td>2.542494</td>\n",
       "      <td>4.690589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>-1.235520e-03</td>\n",
       "      <td>3.155700e-03</td>\n",
       "      <td>2.469000e-05</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>4.055200e-04</td>\n",
       "      <td>1.256230e-03</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>5.437690e-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.545026</td>\n",
       "      <td>4.785378</td>\n",
       "      <td>1.531908</td>\n",
       "      <td>5.373086</td>\n",
       "      <td>4.648320</td>\n",
       "      <td>1.473322</td>\n",
       "      <td>5.091072</td>\n",
       "      <td>1.574975</td>\n",
       "      <td>1.765124</td>\n",
       "      <td>5.094666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>-6.865900e-04</td>\n",
       "      <td>-1.418700e-04</td>\n",
       "      <td>1.259000e-05</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-4.080000e-06</td>\n",
       "      <td>-6.154300e-04</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-9.882000e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.010177</td>\n",
       "      <td>4.740847</td>\n",
       "      <td>1.466086</td>\n",
       "      <td>5.983302</td>\n",
       "      <td>2.663567</td>\n",
       "      <td>1.502218</td>\n",
       "      <td>4.870740</td>\n",
       "      <td>1.676283</td>\n",
       "      <td>1.767206</td>\n",
       "      <td>4.995748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-4.162330e-03</td>\n",
       "      <td>1.482000e-05</td>\n",
       "      <td>-4.852000e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-3.500000e-07</td>\n",
       "      <td>-1.790760e-03</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>1.060500e-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.657907</td>\n",
       "      <td>4.541880</td>\n",
       "      <td>1.774962</td>\n",
       "      <td>5.749403</td>\n",
       "      <td>4.605164</td>\n",
       "      <td>1.802073</td>\n",
       "      <td>4.878438</td>\n",
       "      <td>1.888216</td>\n",
       "      <td>2.153009</td>\n",
       "      <td>4.838809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>-1.469880e-03</td>\n",
       "      <td>-2.282000e-05</td>\n",
       "      <td>9.775900e-04</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-3.391800e-04</td>\n",
       "      <td>1.539060e-03</td>\n",
       "      <td>-0.000961</td>\n",
       "      <td>-7.253300e-04</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.133704</td>\n",
       "      <td>4.429379</td>\n",
       "      <td>2.040637</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>3.456858</td>\n",
       "      <td>2.094011</td>\n",
       "      <td>3.125783</td>\n",
       "      <td>1.307506</td>\n",
       "      <td>2.214062</td>\n",
       "      <td>2.907040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>-2.118700e-04</td>\n",
       "      <td>3.776000e-05</td>\n",
       "      <td>-1.012400e-04</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>-4.989000e-05</td>\n",
       "      <td>6.853000e-05</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>3.237000e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.132965</td>\n",
       "      <td>2.692616</td>\n",
       "      <td>2.174294</td>\n",
       "      <td>2.182031</td>\n",
       "      <td>2.653049</td>\n",
       "      <td>2.062414</td>\n",
       "      <td>2.444778</td>\n",
       "      <td>0.852334</td>\n",
       "      <td>2.391283</td>\n",
       "      <td>2.484687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>1.895540e-03</td>\n",
       "      <td>1.906800e-04</td>\n",
       "      <td>6.893300e-04</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.614800e-04</td>\n",
       "      <td>-1.116350e-03</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-7.887000e-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.061749</td>\n",
       "      <td>5.347277</td>\n",
       "      <td>1.801141</td>\n",
       "      <td>5.645269</td>\n",
       "      <td>5.249315</td>\n",
       "      <td>1.688313</td>\n",
       "      <td>4.541929</td>\n",
       "      <td>1.865450</td>\n",
       "      <td>1.953207</td>\n",
       "      <td>4.540526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-4.175100e-04</td>\n",
       "      <td>-1.312800e-04</td>\n",
       "      <td>-2.200550e-03</td>\n",
       "      <td>-0.002981</td>\n",
       "      <td>3.823900e-04</td>\n",
       "      <td>8.328000e-05</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>-1.302200e-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.514314</td>\n",
       "      <td>5.044381</td>\n",
       "      <td>2.277388</td>\n",
       "      <td>4.887571</td>\n",
       "      <td>4.866520</td>\n",
       "      <td>2.448824</td>\n",
       "      <td>4.692953</td>\n",
       "      <td>4.691697</td>\n",
       "      <td>2.627558</td>\n",
       "      <td>4.693405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>-7.499600e-04</td>\n",
       "      <td>-1.027470e-03</td>\n",
       "      <td>-2.030200e-04</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>5.349300e-04</td>\n",
       "      <td>5.295100e-04</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-1.348380e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.787557</td>\n",
       "      <td>4.435470</td>\n",
       "      <td>1.496647</td>\n",
       "      <td>5.046903</td>\n",
       "      <td>4.501833</td>\n",
       "      <td>1.514530</td>\n",
       "      <td>5.080793</td>\n",
       "      <td>1.599711</td>\n",
       "      <td>1.757028</td>\n",
       "      <td>5.052430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>-1.350500e-03</td>\n",
       "      <td>-1.168900e-04</td>\n",
       "      <td>-9.130300e-04</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>-2.275200e-04</td>\n",
       "      <td>2.045900e-03</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>1.978300e-04</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.137705</td>\n",
       "      <td>5.195469</td>\n",
       "      <td>2.461083</td>\n",
       "      <td>4.537558</td>\n",
       "      <td>4.708219</td>\n",
       "      <td>2.013740</td>\n",
       "      <td>2.804924</td>\n",
       "      <td>1.568977</td>\n",
       "      <td>2.197756</td>\n",
       "      <td>2.510105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>7.390300e-04</td>\n",
       "      <td>1.079600e-04</td>\n",
       "      <td>8.425000e-05</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>1.830000e-06</td>\n",
       "      <td>5.814500e-04</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>-2.064700e-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.022986</td>\n",
       "      <td>4.833194</td>\n",
       "      <td>1.859946</td>\n",
       "      <td>3.754411</td>\n",
       "      <td>4.268626</td>\n",
       "      <td>1.725348</td>\n",
       "      <td>4.953761</td>\n",
       "      <td>1.910598</td>\n",
       "      <td>2.132946</td>\n",
       "      <td>4.893767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>5.116000e-05</td>\n",
       "      <td>9.270000e-06</td>\n",
       "      <td>1.397900e-04</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>4.659000e-05</td>\n",
       "      <td>-2.594000e-05</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>1.240000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.117439</td>\n",
       "      <td>5.049300</td>\n",
       "      <td>1.543578</td>\n",
       "      <td>6.094185</td>\n",
       "      <td>1.612368</td>\n",
       "      <td>1.602073</td>\n",
       "      <td>5.410210</td>\n",
       "      <td>1.575074</td>\n",
       "      <td>1.716376</td>\n",
       "      <td>5.402196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>6.343950e-03</td>\n",
       "      <td>-7.869700e-04</td>\n",
       "      <td>2.766000e-05</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>3.560000e-06</td>\n",
       "      <td>2.252600e-04</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>-7.277900e-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2.032500</td>\n",
       "      <td>4.206039</td>\n",
       "      <td>2.096384</td>\n",
       "      <td>3.015759</td>\n",
       "      <td>4.173101</td>\n",
       "      <td>2.123264</td>\n",
       "      <td>2.316204</td>\n",
       "      <td>0.886103</td>\n",
       "      <td>2.430704</td>\n",
       "      <td>2.358052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2.600000e-07</td>\n",
       "      <td>1.070000e-06</td>\n",
       "      <td>1.403000e-05</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>7.800000e-07</td>\n",
       "      <td>1.603500e-04</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>6.217000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>4.006389</td>\n",
       "      <td>4.239302</td>\n",
       "      <td>1.659012</td>\n",
       "      <td>5.411986</td>\n",
       "      <td>4.577205</td>\n",
       "      <td>1.638946</td>\n",
       "      <td>4.755336</td>\n",
       "      <td>1.858135</td>\n",
       "      <td>1.899330</td>\n",
       "      <td>4.616687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-3.023600e-04</td>\n",
       "      <td>2.564000e-05</td>\n",
       "      <td>-1.762900e-04</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-2.713200e-04</td>\n",
       "      <td>-1.718100e-04</td>\n",
       "      <td>-0.000693</td>\n",
       "      <td>7.915000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>4.986688</td>\n",
       "      <td>4.396297</td>\n",
       "      <td>1.920637</td>\n",
       "      <td>6.289085</td>\n",
       "      <td>4.486528</td>\n",
       "      <td>1.846079</td>\n",
       "      <td>4.869118</td>\n",
       "      <td>1.899704</td>\n",
       "      <td>2.115884</td>\n",
       "      <td>4.846444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>2.745000e-05</td>\n",
       "      <td>3.077000e-05</td>\n",
       "      <td>-3.007000e-04</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-6.050000e-05</td>\n",
       "      <td>7.950000e-06</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-2.978000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2.065161</td>\n",
       "      <td>4.205522</td>\n",
       "      <td>2.088720</td>\n",
       "      <td>3.048243</td>\n",
       "      <td>4.177518</td>\n",
       "      <td>2.116064</td>\n",
       "      <td>2.325778</td>\n",
       "      <td>0.881976</td>\n",
       "      <td>2.434959</td>\n",
       "      <td>2.412001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-8.170000e-06</td>\n",
       "      <td>2.400000e-07</td>\n",
       "      <td>-5.840000e-06</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>1.150000e-06</td>\n",
       "      <td>-1.065000e-05</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-3.100000e-07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>3.344498</td>\n",
       "      <td>4.467428</td>\n",
       "      <td>1.903670</td>\n",
       "      <td>6.223197</td>\n",
       "      <td>4.486436</td>\n",
       "      <td>1.845583</td>\n",
       "      <td>4.913546</td>\n",
       "      <td>1.880310</td>\n",
       "      <td>2.115533</td>\n",
       "      <td>4.848761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>2.720000e-06</td>\n",
       "      <td>1.002000e-05</td>\n",
       "      <td>-3.905500e-04</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-1.105200e-04</td>\n",
       "      <td>9.659000e-05</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>7.930000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>4.472621</td>\n",
       "      <td>4.803782</td>\n",
       "      <td>2.390201</td>\n",
       "      <td>4.857942</td>\n",
       "      <td>4.825112</td>\n",
       "      <td>2.367277</td>\n",
       "      <td>4.663728</td>\n",
       "      <td>4.696148</td>\n",
       "      <td>2.642489</td>\n",
       "      <td>4.661631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>1.995100e-04</td>\n",
       "      <td>5.783000e-04</td>\n",
       "      <td>-9.537000e-05</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>-2.912200e-04</td>\n",
       "      <td>5.087400e-04</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>1.188000e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4.662153</td>\n",
       "      <td>5.089231</td>\n",
       "      <td>2.251104</td>\n",
       "      <td>4.664959</td>\n",
       "      <td>5.083888</td>\n",
       "      <td>2.259487</td>\n",
       "      <td>4.660648</td>\n",
       "      <td>4.695425</td>\n",
       "      <td>2.541469</td>\n",
       "      <td>4.690639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>-2.521970e-03</td>\n",
       "      <td>4.387660e-03</td>\n",
       "      <td>2.249000e-05</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>2.929700e-04</td>\n",
       "      <td>1.817260e-03</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>3.226350e-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2.871505</td>\n",
       "      <td>4.086528</td>\n",
       "      <td>1.979977</td>\n",
       "      <td>3.525518</td>\n",
       "      <td>4.080721</td>\n",
       "      <td>1.988752</td>\n",
       "      <td>2.931714</td>\n",
       "      <td>1.299944</td>\n",
       "      <td>2.236914</td>\n",
       "      <td>2.755317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>1.099300e-04</td>\n",
       "      <td>-2.777000e-05</td>\n",
       "      <td>1.054050e-03</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>8.756000e-05</td>\n",
       "      <td>-8.010000e-05</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-1.852000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>1.567267</td>\n",
       "      <td>5.524019</td>\n",
       "      <td>2.035618</td>\n",
       "      <td>2.887861</td>\n",
       "      <td>4.107110</td>\n",
       "      <td>1.959471</td>\n",
       "      <td>2.763041</td>\n",
       "      <td>1.337432</td>\n",
       "      <td>2.255569</td>\n",
       "      <td>2.628081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-4.176000e-05</td>\n",
       "      <td>4.600000e-07</td>\n",
       "      <td>2.035700e-04</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-2.666000e-05</td>\n",
       "      <td>8.454500e-04</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>4.700000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>5.552606</td>\n",
       "      <td>2.739219</td>\n",
       "      <td>1.543081</td>\n",
       "      <td>4.575202</td>\n",
       "      <td>2.991368</td>\n",
       "      <td>1.471581</td>\n",
       "      <td>5.681852</td>\n",
       "      <td>1.167080</td>\n",
       "      <td>1.778395</td>\n",
       "      <td>5.560789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.493900e-04</td>\n",
       "      <td>8.400000e-07</td>\n",
       "      <td>1.366800e-04</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.233000e-05</td>\n",
       "      <td>-3.858200e-04</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-2.644000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>5.472185</td>\n",
       "      <td>2.849381</td>\n",
       "      <td>1.522810</td>\n",
       "      <td>5.614786</td>\n",
       "      <td>3.111457</td>\n",
       "      <td>1.529164</td>\n",
       "      <td>5.478382</td>\n",
       "      <td>1.177985</td>\n",
       "      <td>1.736212</td>\n",
       "      <td>5.593709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-8.507000e-05</td>\n",
       "      <td>-2.261000e-05</td>\n",
       "      <td>-7.848000e-05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-4.834000e-05</td>\n",
       "      <td>-4.250000e-05</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-2.216000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2.126352</td>\n",
       "      <td>3.666073</td>\n",
       "      <td>1.979160</td>\n",
       "      <td>4.119697</td>\n",
       "      <td>3.354826</td>\n",
       "      <td>2.066917</td>\n",
       "      <td>2.877991</td>\n",
       "      <td>1.330228</td>\n",
       "      <td>2.242460</td>\n",
       "      <td>2.602978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>5.200000e-07</td>\n",
       "      <td>1.360000e-06</td>\n",
       "      <td>2.134000e-05</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-2.070000e-06</td>\n",
       "      <td>5.690000e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.480000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>3.568216</td>\n",
       "      <td>2.102988</td>\n",
       "      <td>1.548253</td>\n",
       "      <td>6.871088</td>\n",
       "      <td>2.577289</td>\n",
       "      <td>1.475460</td>\n",
       "      <td>5.688879</td>\n",
       "      <td>1.362424</td>\n",
       "      <td>1.711404</td>\n",
       "      <td>5.462735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>5.363300e-04</td>\n",
       "      <td>1.109100e-04</td>\n",
       "      <td>7.162800e-04</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>-2.589000e-04</td>\n",
       "      <td>6.557500e-04</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>1.459000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>1.841518</td>\n",
       "      <td>3.077027</td>\n",
       "      <td>1.645710</td>\n",
       "      <td>8.228351</td>\n",
       "      <td>3.021914</td>\n",
       "      <td>1.570281</td>\n",
       "      <td>5.037765</td>\n",
       "      <td>1.758174</td>\n",
       "      <td>1.734467</td>\n",
       "      <td>5.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>-2.745000e-05</td>\n",
       "      <td>6.080000e-06</td>\n",
       "      <td>-1.296100e-04</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>2.097000e-05</td>\n",
       "      <td>1.433600e-04</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>2.350000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>4.671935</td>\n",
       "      <td>4.941351</td>\n",
       "      <td>2.249089</td>\n",
       "      <td>4.655324</td>\n",
       "      <td>4.954179</td>\n",
       "      <td>2.282105</td>\n",
       "      <td>4.664694</td>\n",
       "      <td>4.698467</td>\n",
       "      <td>2.615879</td>\n",
       "      <td>4.663986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>-1.387880e-03</td>\n",
       "      <td>-2.570910e-03</td>\n",
       "      <td>3.905100e-04</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>1.012710e-03</td>\n",
       "      <td>-2.441600e-04</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-2.209900e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2.015260</td>\n",
       "      <td>4.063530</td>\n",
       "      <td>2.094194</td>\n",
       "      <td>2.987104</td>\n",
       "      <td>4.040846</td>\n",
       "      <td>2.124208</td>\n",
       "      <td>2.269376</td>\n",
       "      <td>0.872593</td>\n",
       "      <td>2.408612</td>\n",
       "      <td>2.324926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>6.388400e-04</td>\n",
       "      <td>9.630000e-06</td>\n",
       "      <td>-2.317600e-04</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>5.863000e-05</td>\n",
       "      <td>-2.228200e-04</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>-1.644000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>3.921244</td>\n",
       "      <td>4.818437</td>\n",
       "      <td>1.875558</td>\n",
       "      <td>5.554626</td>\n",
       "      <td>4.759912</td>\n",
       "      <td>1.859222</td>\n",
       "      <td>4.928670</td>\n",
       "      <td>1.863710</td>\n",
       "      <td>2.124240</td>\n",
       "      <td>4.847258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-1.228000e-05</td>\n",
       "      <td>-3.299000e-05</td>\n",
       "      <td>1.092870e-03</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-1.476200e-04</td>\n",
       "      <td>4.080200e-04</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-3.467000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>3.874779</td>\n",
       "      <td>4.457846</td>\n",
       "      <td>1.887299</td>\n",
       "      <td>5.486447</td>\n",
       "      <td>4.372677</td>\n",
       "      <td>1.837808</td>\n",
       "      <td>4.870114</td>\n",
       "      <td>1.873204</td>\n",
       "      <td>2.108493</td>\n",
       "      <td>4.847720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-4.261000e-05</td>\n",
       "      <td>-5.780000e-06</td>\n",
       "      <td>-2.430000e-05</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>5.962000e-05</td>\n",
       "      <td>-4.778800e-04</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-3.486600e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>3.963928</td>\n",
       "      <td>4.352026</td>\n",
       "      <td>1.612773</td>\n",
       "      <td>5.643822</td>\n",
       "      <td>4.479928</td>\n",
       "      <td>1.644757</td>\n",
       "      <td>4.838690</td>\n",
       "      <td>1.904212</td>\n",
       "      <td>1.856930</td>\n",
       "      <td>4.649404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-1.102900e-04</td>\n",
       "      <td>2.754000e-05</td>\n",
       "      <td>1.486700e-04</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-1.948000e-05</td>\n",
       "      <td>4.010000e-05</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-8.390000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>2.011154</td>\n",
       "      <td>4.197348</td>\n",
       "      <td>2.096810</td>\n",
       "      <td>2.986817</td>\n",
       "      <td>4.149439</td>\n",
       "      <td>2.127399</td>\n",
       "      <td>2.284433</td>\n",
       "      <td>0.913284</td>\n",
       "      <td>2.408456</td>\n",
       "      <td>2.336223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.158000e-05</td>\n",
       "      <td>-1.200000e-07</td>\n",
       "      <td>8.780000e-05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-1.799000e-05</td>\n",
       "      <td>-2.218000e-05</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-7.180000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>4.605340</td>\n",
       "      <td>5.009713</td>\n",
       "      <td>2.105514</td>\n",
       "      <td>4.690083</td>\n",
       "      <td>5.011017</td>\n",
       "      <td>2.121903</td>\n",
       "      <td>4.636420</td>\n",
       "      <td>4.699239</td>\n",
       "      <td>2.589149</td>\n",
       "      <td>4.647546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>-7.892000e-05</td>\n",
       "      <td>5.476500e-04</td>\n",
       "      <td>1.388900e-04</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>2.929000e-05</td>\n",
       "      <td>-2.357600e-04</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-2.569900e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>4.840569</td>\n",
       "      <td>3.614056</td>\n",
       "      <td>1.680485</td>\n",
       "      <td>4.057771</td>\n",
       "      <td>3.663162</td>\n",
       "      <td>1.739799</td>\n",
       "      <td>4.342387</td>\n",
       "      <td>1.828988</td>\n",
       "      <td>1.969188</td>\n",
       "      <td>4.430486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-3.855600e-04</td>\n",
       "      <td>1.099500e-04</td>\n",
       "      <td>6.237200e-04</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>2.074500e-04</td>\n",
       "      <td>-1.820800e-04</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>1.093500e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>4.532464</td>\n",
       "      <td>4.835602</td>\n",
       "      <td>2.670902</td>\n",
       "      <td>4.835504</td>\n",
       "      <td>4.810109</td>\n",
       "      <td>2.622385</td>\n",
       "      <td>4.692667</td>\n",
       "      <td>4.703043</td>\n",
       "      <td>2.677981</td>\n",
       "      <td>4.701355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>-1.730220e-03</td>\n",
       "      <td>3.027230e-03</td>\n",
       "      <td>1.830000e-05</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>1.003100e-04</td>\n",
       "      <td>-1.630400e-04</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>1.056270e-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1.634297</td>\n",
       "      <td>3.084884</td>\n",
       "      <td>1.988443</td>\n",
       "      <td>4.358225</td>\n",
       "      <td>3.338326</td>\n",
       "      <td>2.085994</td>\n",
       "      <td>2.930036</td>\n",
       "      <td>1.294838</td>\n",
       "      <td>2.215453</td>\n",
       "      <td>2.714492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-2.942000e-05</td>\n",
       "      <td>4.200000e-06</td>\n",
       "      <td>-9.674000e-05</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-1.010000e-06</td>\n",
       "      <td>1.083000e-05</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>4.670000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>3.009816</td>\n",
       "      <td>2.518919</td>\n",
       "      <td>2.139102</td>\n",
       "      <td>2.393948</td>\n",
       "      <td>2.329509</td>\n",
       "      <td>2.026586</td>\n",
       "      <td>2.465100</td>\n",
       "      <td>0.864249</td>\n",
       "      <td>2.376168</td>\n",
       "      <td>2.475183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-3.895300e-04</td>\n",
       "      <td>8.685000e-05</td>\n",
       "      <td>-1.406000e-05</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>4.110000e-06</td>\n",
       "      <td>3.295700e-04</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>9.969000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>4.449208</td>\n",
       "      <td>4.414223</td>\n",
       "      <td>1.879341</td>\n",
       "      <td>5.252711</td>\n",
       "      <td>4.270740</td>\n",
       "      <td>1.903770</td>\n",
       "      <td>4.871369</td>\n",
       "      <td>1.866756</td>\n",
       "      <td>2.093739</td>\n",
       "      <td>4.855446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>6.190000e-04</td>\n",
       "      <td>1.302000e-05</td>\n",
       "      <td>1.308700e-03</td>\n",
       "      <td>-0.001545</td>\n",
       "      <td>-2.460900e-04</td>\n",
       "      <td>1.197200e-04</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>6.200000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>3.188473</td>\n",
       "      <td>3.757680</td>\n",
       "      <td>2.081962</td>\n",
       "      <td>4.325406</td>\n",
       "      <td>3.471321</td>\n",
       "      <td>2.041253</td>\n",
       "      <td>2.465361</td>\n",
       "      <td>0.892285</td>\n",
       "      <td>2.388412</td>\n",
       "      <td>2.439551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>-5.250000e-06</td>\n",
       "      <td>6.300000e-07</td>\n",
       "      <td>4.309800e-04</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-6.921000e-05</td>\n",
       "      <td>5.303000e-05</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>1.900000e-07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>3.025133</td>\n",
       "      <td>4.813557</td>\n",
       "      <td>1.856241</td>\n",
       "      <td>3.763350</td>\n",
       "      <td>4.248315</td>\n",
       "      <td>1.724209</td>\n",
       "      <td>4.959218</td>\n",
       "      <td>1.908251</td>\n",
       "      <td>2.135596</td>\n",
       "      <td>4.899865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>1.797200e-04</td>\n",
       "      <td>-8.390000e-06</td>\n",
       "      <td>-3.340000e-06</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-2.026000e-05</td>\n",
       "      <td>-8.620400e-04</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>-1.998300e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>4.709558</td>\n",
       "      <td>4.395216</td>\n",
       "      <td>1.888074</td>\n",
       "      <td>5.205003</td>\n",
       "      <td>4.270995</td>\n",
       "      <td>1.841076</td>\n",
       "      <td>4.847654</td>\n",
       "      <td>1.871276</td>\n",
       "      <td>2.088522</td>\n",
       "      <td>4.840115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-1.995200e-04</td>\n",
       "      <td>-5.345000e-05</td>\n",
       "      <td>-1.408800e-04</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>2.762000e-05</td>\n",
       "      <td>-6.280000e-06</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-3.067000e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2.158332</td>\n",
       "      <td>3.240736</td>\n",
       "      <td>1.927958</td>\n",
       "      <td>3.355644</td>\n",
       "      <td>4.338253</td>\n",
       "      <td>1.977688</td>\n",
       "      <td>2.832004</td>\n",
       "      <td>1.279006</td>\n",
       "      <td>2.253503</td>\n",
       "      <td>2.624498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>6.980000e-06</td>\n",
       "      <td>-3.180000e-06</td>\n",
       "      <td>-1.410000e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-3.500000e-07</td>\n",
       "      <td>-3.210000e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-1.010000e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lhx       lhy       lhz       rhx       rhy       rhz        hx  \\\n",
       "0    4.205590  4.694525  1.869073  4.921949  4.029522  1.889851  4.851381   \n",
       "1    3.667537  5.315720  1.828394  5.496964  5.049758  1.650158  4.452520   \n",
       "2    3.687988  2.772793  1.626460  6.565267  2.711560  1.630421  5.026713   \n",
       "3    4.726025  4.561223  1.902970  6.186168  4.496355  1.858916  4.920242   \n",
       "4    2.289227  4.712777  2.227426  2.993593  4.458786  2.288884  2.370949   \n",
       "5    4.109002  3.927355  1.501798  6.920993  3.501003  1.423287  5.430639   \n",
       "6    4.668501  4.950205  2.279571  4.796742  5.128264  2.298723  4.656317   \n",
       "7    1.272500  5.525830  2.119054  3.766633  5.583711  2.266399  2.786795   \n",
       "8    4.330683  5.037382  1.891318  5.021062  5.152056  1.907732  4.879743   \n",
       "9    4.421911  3.245796  1.353590  5.741972  3.886645  1.492309  5.062042   \n",
       "10   1.920042  3.978703  2.211195  2.968426  0.834077  2.202471  2.259430   \n",
       "11   5.026071  4.238918  1.941478  6.304251  4.498418  1.842593  4.893420   \n",
       "12   2.199439  4.980598  2.003031  2.549979  4.901636  2.009590  2.720113   \n",
       "13   4.780814  4.560586  1.483252  4.966421  4.546110  1.496978  4.976627   \n",
       "14   4.556494  5.099709  2.419096  4.669863  5.024026  2.343937  4.677213   \n",
       "15   5.265414  3.057349  1.468588  4.556957  3.596444  1.530195  5.581937   \n",
       "16   1.853124  4.676322  1.968942  3.509686  4.109926  1.983233  2.848704   \n",
       "17   3.660271  5.251965  1.793846  5.698182  1.737274  1.751455  4.181806   \n",
       "18   4.663677  5.086694  2.248109  4.663788  5.086501  2.247355  4.661151   \n",
       "19   4.545026  4.785378  1.531908  5.373086  4.648320  1.473322  5.091072   \n",
       "20   5.010177  4.740847  1.466086  5.983302  2.663567  1.502218  4.870740   \n",
       "21   4.657907  4.541880  1.774962  5.749403  4.605164  1.802073  4.878438   \n",
       "22   1.133704  4.429379  2.040637  5.015625  3.456858  2.094011  3.125783   \n",
       "23   3.132965  2.692616  2.174294  2.182031  2.653049  2.062414  2.444778   \n",
       "24   4.061749  5.347277  1.801141  5.645269  5.249315  1.688313  4.541929   \n",
       "25   4.514314  5.044381  2.277388  4.887571  4.866520  2.448824  4.692953   \n",
       "26   4.787557  4.435470  1.496647  5.046903  4.501833  1.514530  5.080793   \n",
       "27   1.137705  5.195469  2.461083  4.537558  4.708219  2.013740  2.804924   \n",
       "28   3.022986  4.833194  1.859946  3.754411  4.268626  1.725348  4.953761   \n",
       "29   5.117439  5.049300  1.543578  6.094185  1.612368  1.602073  5.410210   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "320  2.032500  4.206039  2.096384  3.015759  4.173101  2.123264  2.316204   \n",
       "340  4.006389  4.239302  1.659012  5.411986  4.577205  1.638946  4.755336   \n",
       "360  4.986688  4.396297  1.920637  6.289085  4.486528  1.846079  4.869118   \n",
       "390  2.065161  4.205522  2.088720  3.048243  4.177518  2.116064  2.325778   \n",
       "396  3.344498  4.467428  1.903670  6.223197  4.486436  1.845583  4.913546   \n",
       "399  4.472621  4.803782  2.390201  4.857942  4.825112  2.367277  4.663728   \n",
       "406  4.662153  5.089231  2.251104  4.664959  5.083888  2.259487  4.660648   \n",
       "409  2.871505  4.086528  1.979977  3.525518  4.080721  1.988752  2.931714   \n",
       "428  1.567267  5.524019  2.035618  2.887861  4.107110  1.959471  2.763041   \n",
       "435  5.552606  2.739219  1.543081  4.575202  2.991368  1.471581  5.681852   \n",
       "437  5.472185  2.849381  1.522810  5.614786  3.111457  1.529164  5.478382   \n",
       "440  2.126352  3.666073  1.979160  4.119697  3.354826  2.066917  2.877991   \n",
       "451  3.568216  2.102988  1.548253  6.871088  2.577289  1.475460  5.688879   \n",
       "459  1.841518  3.077027  1.645710  8.228351  3.021914  1.570281  5.037765   \n",
       "485  4.671935  4.941351  2.249089  4.655324  4.954179  2.282105  4.664694   \n",
       "491  2.015260  4.063530  2.094194  2.987104  4.040846  2.124208  2.269376   \n",
       "502  3.921244  4.818437  1.875558  5.554626  4.759912  1.859222  4.928670   \n",
       "506  3.874779  4.457846  1.887299  5.486447  4.372677  1.837808  4.870114   \n",
       "509  3.963928  4.352026  1.612773  5.643822  4.479928  1.644757  4.838690   \n",
       "524  2.011154  4.197348  2.096810  2.986817  4.149439  2.127399  2.284433   \n",
       "525  4.605340  5.009713  2.105514  4.690083  5.011017  2.121903  4.636420   \n",
       "549  4.840569  3.614056  1.680485  4.057771  3.663162  1.739799  4.342387   \n",
       "553  4.532464  4.835602  2.670902  4.835504  4.810109  2.622385  4.692667   \n",
       "554  1.634297  3.084884  1.988443  4.358225  3.338326  2.085994  2.930036   \n",
       "562  3.009816  2.518919  2.139102  2.393948  2.329509  2.026586  2.465100   \n",
       "567  4.449208  4.414223  1.879341  5.252711  4.270740  1.903770  4.871369   \n",
       "571  3.188473  3.757680  2.081962  4.325406  3.471321  2.041253  2.465361   \n",
       "576  3.025133  4.813557  1.856241  3.763350  4.248315  1.724209  4.959218   \n",
       "580  4.709558  4.395216  1.888074  5.205003  4.270995  1.841076  4.847654   \n",
       "589  2.158332  3.240736  1.927958  3.355644  4.338253  1.977688  2.832004   \n",
       "\n",
       "           hy        hz        sx  ...      arhx          arhy          arhz  \\\n",
       "0    1.856576  2.092771  4.847641  ...  0.000940  3.774520e-03  5.399800e-04   \n",
       "1    1.847379  1.981042  4.470696  ...  0.001386  9.019000e-04  6.443000e-05   \n",
       "2    1.773879  1.677735  5.099942  ...  0.000232 -1.383200e-03  4.241600e-04   \n",
       "3    1.872385  2.126026  4.854091  ...  0.000949  7.901100e-04 -1.390000e-05   \n",
       "4    0.869894  2.407945  2.484432  ...  0.000001 -1.500000e-07  2.600000e-07   \n",
       "5    1.736059  1.697598  5.544961  ...  0.000080  5.679420e-03  3.864300e-04   \n",
       "6    4.701049  2.555991  4.683853  ... -0.000246  2.278100e-04 -2.087300e-04   \n",
       "7    1.327088  2.212436  2.523509  ... -0.000087  5.166000e-05  4.850000e-05   \n",
       "8    1.844396  2.115820  4.854716  ...  0.000316  2.432900e-04  1.842100e-04   \n",
       "9    1.622844  1.738860  5.003149  ... -0.000421  2.066430e-03  2.296200e-04   \n",
       "10   0.845343  2.406115  2.445755  ...  0.000011 -3.771000e-05  9.450000e-06   \n",
       "11   1.859839  2.126839  4.859129  ... -0.000143  3.359630e-03  7.484200e-04   \n",
       "12   1.314647  2.221931  2.663610  ...  0.000335 -1.818700e-04 -7.426000e-05   \n",
       "13   1.656472  1.769066  5.035172  ...  0.003585 -2.502310e-03 -4.183500e-04   \n",
       "14   4.693687  2.613214  4.683428  ... -0.000467  7.982000e-05  2.511400e-04   \n",
       "15   1.251014  1.763594  5.482471  ... -0.002868  1.979050e-03  8.914700e-04   \n",
       "16   1.303667  2.227088  2.637406  ... -0.000049  6.521000e-05  4.460000e-06   \n",
       "17   1.805099  1.966767  4.436745  ...  0.000204 -5.050850e-03 -4.702400e-04   \n",
       "18   4.695288  2.542494  4.690589  ...  0.000834 -1.235520e-03  3.155700e-03   \n",
       "19   1.574975  1.765124  5.094666  ... -0.000631 -6.865900e-04 -1.418700e-04   \n",
       "20   1.676283  1.767206  4.995748  ... -0.005872 -4.162330e-03  1.482000e-05   \n",
       "21   1.888216  2.153009  4.838809  ...  0.002166 -1.469880e-03 -2.282000e-05   \n",
       "22   1.307506  2.214062  2.907040  ...  0.000218 -2.118700e-04  3.776000e-05   \n",
       "23   0.852334  2.391283  2.484687  ... -0.001066  1.895540e-03  1.906800e-04   \n",
       "24   1.865450  1.953207  4.540526  ... -0.000014 -4.175100e-04 -1.312800e-04   \n",
       "25   4.691697  2.627558  4.693405  ...  0.000285 -7.499600e-04 -1.027470e-03   \n",
       "26   1.599711  1.757028  5.052430  ...  0.004064 -1.350500e-03 -1.168900e-04   \n",
       "27   1.568977  2.197756  2.510105  ...  0.000496  7.390300e-04  1.079600e-04   \n",
       "28   1.910598  2.132946  4.893767  ... -0.000077  5.116000e-05  9.270000e-06   \n",
       "29   1.575074  1.716376  5.402196  ...  0.002310  6.343950e-03 -7.869700e-04   \n",
       "..        ...       ...       ...  ...       ...           ...           ...   \n",
       "320  0.886103  2.430704  2.358052  ...  0.000013  2.600000e-07  1.070000e-06   \n",
       "340  1.858135  1.899330  4.616687  ... -0.000147 -3.023600e-04  2.564000e-05   \n",
       "360  1.899704  2.115884  4.846444  ... -0.000175  2.745000e-05  3.077000e-05   \n",
       "390  0.881976  2.434959  2.412001  ... -0.000006 -8.170000e-06  2.400000e-07   \n",
       "396  1.880310  2.115533  4.848761  ... -0.000027  2.720000e-06  1.002000e-05   \n",
       "399  4.696148  2.642489  4.661631  ...  0.000936  1.995100e-04  5.783000e-04   \n",
       "406  4.695425  2.541469  4.690639  ...  0.001842 -2.521970e-03  4.387660e-03   \n",
       "409  1.299944  2.236914  2.755317  ... -0.000335  1.099300e-04 -2.777000e-05   \n",
       "428  1.337432  2.255569  2.628081  ...  0.000003 -4.176000e-05  4.600000e-07   \n",
       "435  1.167080  1.778395  5.560789  ...  0.000007  1.493900e-04  8.400000e-07   \n",
       "437  1.177985  1.736212  5.593709  ... -0.000058 -8.507000e-05 -2.261000e-05   \n",
       "440  1.330228  2.242460  2.602978  ...  0.000023  5.200000e-07  1.360000e-06   \n",
       "451  1.362424  1.711404  5.462735  ...  0.000782  5.363300e-04  1.109100e-04   \n",
       "459  1.758174  1.734467  5.049960  ...  0.000127 -2.745000e-05  6.080000e-06   \n",
       "485  4.698467  2.615879  4.663986  ... -0.001337 -1.387880e-03 -2.570910e-03   \n",
       "491  0.872593  2.408612  2.324926  ... -0.000031  6.388400e-04  9.630000e-06   \n",
       "502  1.863710  2.124240  4.847258  ...  0.000063 -1.228000e-05 -3.299000e-05   \n",
       "506  1.873204  2.108493  4.847720  ... -0.000019 -4.261000e-05 -5.780000e-06   \n",
       "509  1.904212  1.856930  4.649404  ...  0.000206 -1.102900e-04  2.754000e-05   \n",
       "524  0.913284  2.408456  2.336223  ...  0.000003  1.158000e-05 -1.200000e-07   \n",
       "525  4.699239  2.589149  4.647546  ...  0.000128 -7.892000e-05  5.476500e-04   \n",
       "549  1.828988  1.969188  4.430486  ... -0.000177 -3.855600e-04  1.099500e-04   \n",
       "553  4.703043  2.677981  4.701355  ... -0.000398 -1.730220e-03  3.027230e-03   \n",
       "554  1.294838  2.215453  2.714492  ... -0.000002 -2.942000e-05  4.200000e-06   \n",
       "562  0.864249  2.376168  2.475183  ...  0.000282 -3.895300e-04  8.685000e-05   \n",
       "567  1.866756  2.093739  4.855446  ...  0.000118  6.190000e-04  1.302000e-05   \n",
       "571  0.892285  2.388412  2.439551  ...  0.000102 -5.250000e-06  6.300000e-07   \n",
       "576  1.908251  2.135596  4.899865  ... -0.000046  1.797200e-04 -8.390000e-06   \n",
       "580  1.871276  2.088522  4.840115  ... -0.000163 -1.995200e-04 -5.345000e-05   \n",
       "589  1.279006  2.253503  2.624498  ... -0.000009  6.980000e-06 -3.180000e-06   \n",
       "\n",
       "             alwx      alwy          alwz          arwx      arwy  \\\n",
       "0    1.797380e-03 -0.000401 -7.289700e-04  7.043100e-04  0.002726   \n",
       "1   -2.201000e-05 -0.000018 -9.400000e-07  3.954800e-04  0.000107   \n",
       "2   -5.700100e-04 -0.003331  2.262100e-04  8.658100e-04 -0.002652   \n",
       "3    1.242400e-04 -0.000161  4.246000e-05  4.017000e-05  0.000250   \n",
       "4    7.100000e-07  0.000003 -1.600000e-07  5.400000e-07 -0.000002   \n",
       "5   -1.660200e-03  0.002122 -5.743000e-05  6.865130e-03  0.002959   \n",
       "6    2.952700e-04 -0.000119  3.555000e-05 -1.612900e-04 -0.000223   \n",
       "7   -7.413000e-05  0.000056  6.573000e-05 -7.888000e-05  0.000036   \n",
       "8    6.456500e-04  0.000177 -2.107000e-05  2.957500e-04 -0.000032   \n",
       "9   -1.073970e-03 -0.000062 -2.757300e-04  4.522600e-04  0.001330   \n",
       "10  -9.300000e-06  0.000002  6.770000e-06  6.300000e-06 -0.000017   \n",
       "11   2.095370e-03  0.001005  1.271600e-04 -6.258680e-03  0.003334   \n",
       "12   2.940500e-04 -0.000204 -4.416000e-05 -2.099800e-04  0.000050   \n",
       "13  -9.879400e-04  0.001440 -8.126000e-05  2.152710e-03 -0.002860   \n",
       "14  -6.833900e-04 -0.000142 -3.342100e-04 -1.105830e-03  0.000371   \n",
       "15   2.652100e-04 -0.000865 -2.095200e-04  3.827700e-04 -0.001109   \n",
       "16   1.880600e-04 -0.000149 -3.450000e-05 -9.043000e-05  0.000223   \n",
       "17  -2.896000e-05  0.000135 -6.310000e-06 -1.048500e-04 -0.000276   \n",
       "18   2.469000e-05  0.000212  4.055200e-04  1.256230e-03 -0.001273   \n",
       "19   1.259000e-05 -0.000022 -4.080000e-06 -6.154300e-04  0.000345   \n",
       "20  -4.852000e-05  0.000098 -3.500000e-07 -1.790760e-03  0.001627   \n",
       "21   9.775900e-04 -0.000041 -3.391800e-04  1.539060e-03 -0.000961   \n",
       "22  -1.012400e-04  0.000151 -4.989000e-05  6.853000e-05 -0.000102   \n",
       "23   6.893300e-04  0.000015  1.614800e-04 -1.116350e-03 -0.000465   \n",
       "24  -2.200550e-03 -0.002981  3.823900e-04  8.328000e-05 -0.000492   \n",
       "25  -2.030200e-04  0.000163  5.349300e-04  5.295100e-04 -0.001252   \n",
       "26  -9.130300e-04  0.000508 -2.275200e-04  2.045900e-03 -0.000012   \n",
       "27   8.425000e-05 -0.000229  1.830000e-06  5.814500e-04  0.001575   \n",
       "28   1.397900e-04  0.000238  4.659000e-05 -2.594000e-05 -0.000028   \n",
       "29   2.766000e-05  0.000748  3.560000e-06  2.252600e-04  0.005393   \n",
       "..            ...       ...           ...           ...       ...   \n",
       "320  1.403000e-05 -0.000002  7.800000e-07  1.603500e-04 -0.000052   \n",
       "340 -1.762900e-04 -0.000608 -2.713200e-04 -1.718100e-04 -0.000693   \n",
       "360 -3.007000e-04  0.000050 -6.050000e-05  7.950000e-06 -0.000174   \n",
       "390 -5.840000e-06 -0.000010  1.150000e-06 -1.065000e-05 -0.000005   \n",
       "396 -3.905500e-04 -0.000124 -1.105200e-04  9.659000e-05  0.000116   \n",
       "399 -9.537000e-05 -0.000355 -2.912200e-04  5.087400e-04  0.000091   \n",
       "406  2.249000e-05  0.000157  2.929700e-04  1.817260e-03 -0.001352   \n",
       "409  1.054050e-03 -0.000451  8.756000e-05 -8.010000e-05  0.000073   \n",
       "428  2.035700e-04  0.000174 -2.666000e-05  8.454500e-04 -0.000045   \n",
       "435  1.366800e-04  0.000008  2.233000e-05 -3.858200e-04 -0.000036   \n",
       "437 -7.848000e-05  0.000044 -4.834000e-05 -4.250000e-05 -0.000081   \n",
       "440  2.134000e-05 -0.000016 -2.070000e-06  5.690000e-06  0.000009   \n",
       "451  7.162800e-04  0.001131 -2.589000e-04  6.557500e-04  0.000335   \n",
       "459 -1.296100e-04  0.000034  2.097000e-05  1.433600e-04 -0.000033   \n",
       "485  3.905100e-04  0.000186  1.012710e-03 -2.441600e-04  0.000199   \n",
       "491 -2.317600e-04  0.000850  5.863000e-05 -2.228200e-04  0.000671   \n",
       "502  1.092870e-03  0.000091 -1.476200e-04  4.080200e-04  0.000067   \n",
       "506 -2.430000e-05 -0.000018  5.962000e-05 -4.778800e-04  0.000430   \n",
       "509  1.486700e-04  0.000030 -1.948000e-05  4.010000e-05 -0.000013   \n",
       "524  8.780000e-05  0.000044 -1.799000e-05 -2.218000e-05  0.000043   \n",
       "525  1.388900e-04  0.000075  2.929000e-05 -2.357600e-04  0.000150   \n",
       "549  6.237200e-04 -0.000775  2.074500e-04 -1.820800e-04 -0.000391   \n",
       "553  1.830000e-05  0.000116  1.003100e-04 -1.630400e-04 -0.000596   \n",
       "554 -9.674000e-05 -0.000247 -1.010000e-06  1.083000e-05 -0.000025   \n",
       "562 -1.406000e-05 -0.000064  4.110000e-06  3.295700e-04 -0.000398   \n",
       "567  1.308700e-03 -0.001545 -2.460900e-04  1.197200e-04  0.000552   \n",
       "571  4.309800e-04 -0.000069 -6.921000e-05  5.303000e-05 -0.000050   \n",
       "576 -3.340000e-06  0.000170 -2.026000e-05 -8.620400e-04  0.000379   \n",
       "580 -1.408800e-04 -0.000044  2.762000e-05 -6.280000e-06  0.000070   \n",
       "589 -1.410000e-06  0.000004 -3.500000e-07 -3.210000e-06  0.000005   \n",
       "\n",
       "             arwz  Action  \n",
       "0    4.028200e-04       2  \n",
       "1    6.380000e-05       4  \n",
       "2    3.404000e-04       2  \n",
       "3    9.127000e-05       4  \n",
       "4    6.500000e-07       0  \n",
       "5   -2.456900e-04       4  \n",
       "6   -2.520000e-05       1  \n",
       "7    3.841000e-05       1  \n",
       "8    1.021800e-04       1  \n",
       "9    4.323600e-04       2  \n",
       "10   4.950000e-06       2  \n",
       "11   8.990200e-04       3  \n",
       "12  -2.683000e-05       0  \n",
       "13  -4.725400e-04       1  \n",
       "14  -7.919800e-04       1  \n",
       "15   2.538800e-04       2  \n",
       "16  -3.896000e-05       3  \n",
       "17   4.050000e-06       4  \n",
       "18   5.437690e-03       3  \n",
       "19  -9.882000e-05       0  \n",
       "20   1.060500e-04       1  \n",
       "21  -7.253300e-04       4  \n",
       "22   3.237000e-05       1  \n",
       "23  -7.887000e-05       4  \n",
       "24  -1.302200e-04       1  \n",
       "25  -1.348380e-03       1  \n",
       "26   1.978300e-04       4  \n",
       "27  -2.064700e-04       1  \n",
       "28   1.240000e-06       3  \n",
       "29  -7.277900e-04       2  \n",
       "..            ...     ...  \n",
       "320  6.217000e-05       3  \n",
       "340  7.915000e-05       3  \n",
       "360 -2.978000e-05       3  \n",
       "390 -3.100000e-07       3  \n",
       "396  7.930000e-06       3  \n",
       "399  1.188000e-04       3  \n",
       "406  3.226350e-03       3  \n",
       "409 -1.852000e-05       3  \n",
       "428  4.700000e-05       3  \n",
       "435 -2.644000e-05       3  \n",
       "437 -2.216000e-05       3  \n",
       "440  3.480000e-06       3  \n",
       "451  1.459000e-05       3  \n",
       "459  2.350000e-06       3  \n",
       "485 -2.209900e-04       3  \n",
       "491 -1.644000e-05       3  \n",
       "502 -3.467000e-05       3  \n",
       "506 -3.486600e-04       3  \n",
       "509 -8.390000e-06       3  \n",
       "524 -7.180000e-06       3  \n",
       "525 -2.569900e-04       3  \n",
       "549  1.093500e-04       3  \n",
       "553  1.056270e-03       3  \n",
       "554  4.670000e-06       3  \n",
       "562  9.969000e-05       3  \n",
       "567  6.200000e-06       3  \n",
       "571  1.900000e-07       3  \n",
       "576 -1.998300e-04       3  \n",
       "580 -3.067000e-05       3  \n",
       "589 -1.010000e-06       3  \n",
       "\n",
       "[733 rows x 43 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    175\n",
       "0    152\n",
       "4    142\n",
       "3    140\n",
       "1    124\n",
       "Name: Action, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new[\"Action\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lhx', 'lhy', 'lhz', 'rhx', 'rhy', 'rhz', 'hx', 'hy', 'hz', 'sx', 'sy',\n",
       "       'sz', 'lwx', 'lwy', 'lwz', 'rwx', 'rwy', 'rwz', 'vlhx', 'vlhy', 'vlhz',\n",
       "       'vrhx', 'vrhy', 'vrhz', 'vlwx', 'vlwy', 'vlwz', 'vrwx', 'vrwy', 'vrwz',\n",
       "       'alhx', 'alhy', 'alhz', 'arhx', 'arhy', 'arhz', 'alwx', 'alwy', 'alwz',\n",
       "       'arwx', 'arwy', 'arwz', 'Action'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_new.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "print(len(columns))\n",
    "\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if corr.iloc[i,j] >= 0.9:\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "print(\"new col\",columns)\n",
    "\n",
    "selected_columns = data_new.columns[columns]\n",
    "print(len(selected_columns))\n",
    "print(selected_columns[1:].values)\n",
    "X_features_transformed = data_new[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_transformed[\"Action\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.formula.api as sm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def backwardElimination(x, Y, sl, columns):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    columns = np.delete(columns, j)\n",
    "                    \n",
    "    regressor_OLS.summary()\n",
    "    return x, columns\n",
    "\n",
    "\n",
    "SL = 0.05\n",
    "selected_columns = selected_columns[:-1].values\n",
    "data_modeled, selected_columns = backwardElimination(X_features_transformed.iloc[:,:29].values, X_features_transformed.iloc[:,29].values, SL, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = X_features_transformed[['Action']]\n",
    "train = pd.DataFrame(data = data_modeled, columns = selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "train.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train.values, result.values, test_size = 0.2)\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=12),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    print(\"----------------\",name,\"----------------\")\n",
    "    clf.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_test)\n",
    "    score = clf.score(x_test, y_test)\n",
    "    print(\"score : \", score)\n",
    "    print(\"confusion_matrix\", confusion_matrix(y_test, preds))\n",
    "    print(\"classification_report\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.columns\n",
    "data_new_train = data_new.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_new_train.values, result.values, test_size = 0.2)\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=12),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    print(\"----------------\",name,\"----------------\")\n",
    "    clf.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_test)\n",
    "    score = clf.score(x_test, y_test)\n",
    "    print(\"score : \", score)\n",
    "    print(\"confusion_matrix\", confusion_matrix(y_test, preds))\n",
    "    print(\"classification_report\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train = X_features_transformed.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_new_train.values, result.values, test_size = 0.2)\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=12),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    print(\"----------------\",name,\"----------------\")\n",
    "    clf.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_test)\n",
    "    score = clf.score(x_test, y_test)\n",
    "    print(\"score : \", score)\n",
    "    print(\"confusion_matrix\", confusion_matrix(y_test, preds))\n",
    "    print(\"classification_report\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lhx', 'lhy', 'lhz', 'rhx', 'rhy', 'rhz', 'hx', 'hy', 'hz', 'sx',\n",
       "       'sy', 'sz', 'lwx', 'lwy', 'lwz', 'rwx', 'rwy', 'rwz', 'vlhx',\n",
       "       'vlhy', 'vlhz', 'vrhx', 'vrhy', 'vrhz', 'vlwx', 'vlwy', 'vlwz',\n",
       "       'vrwx', 'vrwy', 'vrwz', 'alhx', 'alhy', 'alhz', 'arhx', 'arhy',\n",
       "       'arhz', 'alwx', 'alwy', 'alwz', 'arwx', 'arwy', 'arwz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = data_new.columns\n",
    "selected_columns = selected_columns[:-1].values\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.formula.api as sm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def backwardElimination(x, Y, sl, columns):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    columns = np.delete(columns, j)\n",
    "                    \n",
    "    regressor_OLS.summary()\n",
    "    return x, columns\n",
    "\n",
    "\n",
    "SL = 0.09\n",
    "#selected_columns = selected_columns[:-1].values\n",
    "data_modeled, selected_columns = backwardElimination(data_new.iloc[:,:-1].values, data_new.iloc[:,-1].values, SL, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lhy', 'rhy', 'rhz', 'hy', 'sy', 'sz', 'lwx', 'lwy', 'rwx', 'rwy',\n",
       "       'vrhx', 'vrhy', 'vrhz', 'vlwy', 'vrwz', 'alhy', 'alhz', 'arhx',\n",
       "       'arhz', 'alwx', 'alwz', 'arwy', 'arwz'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(733, 23)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_modeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_new[['Action']]\n",
    "X_data_modeled = pd.DataFrame(data = data_modeled, columns = selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Nearest Neighbors ----------------\n",
      "score :  0.6394557823129252\n",
      "confusion_matrix [[30  3  0  1  2]\n",
      " [ 8  7  2  5  2]\n",
      " [ 1  6 19  1  3]\n",
      " [ 0  2  3 21  1]\n",
      " [ 3  3  4  3 17]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        36\n",
      "           1       0.33      0.29      0.31        24\n",
      "           2       0.68      0.63      0.66        30\n",
      "           3       0.68      0.78      0.72        27\n",
      "           4       0.68      0.57      0.62        30\n",
      "\n",
      "    accuracy                           0.64       147\n",
      "   macro avg       0.62      0.62      0.62       147\n",
      "weighted avg       0.63      0.64      0.63       147\n",
      "\n",
      "---------------- Linear SVM ----------------\n",
      "score :  0.20408163265306123\n",
      "confusion_matrix [[ 0  0 36  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 30  0  0]\n",
      " [ 0  0 27  0  0]\n",
      " [ 0  0 30  0  0]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.20      1.00      0.34        30\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.20       147\n",
      "   macro avg       0.04      0.20      0.07       147\n",
      "weighted avg       0.04      0.20      0.07       147\n",
      "\n",
      "---------------- RBF SVM ----------------\n",
      "score :  0.6938775510204082\n",
      "confusion_matrix [[30  3  0  0  3]\n",
      " [ 4  8  3  4  5]\n",
      " [ 0  3 26  1  0]\n",
      " [ 0  3  1 23  0]\n",
      " [ 5  1  6  3 15]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        36\n",
      "           1       0.44      0.33      0.38        24\n",
      "           2       0.72      0.87      0.79        30\n",
      "           3       0.74      0.85      0.79        27\n",
      "           4       0.65      0.50      0.57        30\n",
      "\n",
      "    accuracy                           0.69       147\n",
      "   macro avg       0.67      0.68      0.67       147\n",
      "weighted avg       0.68      0.69      0.68       147\n",
      "\n",
      "---------------- Gaussian Process ----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\ipykernel_launcher.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.6122448979591837\n",
      "confusion_matrix [[34  0  1  0  1]\n",
      " [ 8  0  7  7  2]\n",
      " [ 1  0 27  2  0]\n",
      " [ 0  0  1 26  0]\n",
      " [ 5  0 16  6  3]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81        36\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.52      0.90      0.66        30\n",
      "           3       0.63      0.96      0.76        27\n",
      "           4       0.50      0.10      0.17        30\n",
      "\n",
      "    accuracy                           0.61       147\n",
      "   macro avg       0.47      0.58      0.48       147\n",
      "weighted avg       0.50      0.61      0.51       147\n",
      "\n",
      "---------------- Decision Tree ----------------\n",
      "score :  0.6326530612244898\n",
      "confusion_matrix [[29  2  0  1  4]\n",
      " [ 6  7  6  1  4]\n",
      " [ 1  8 17  3  1]\n",
      " [ 0  0  0 27  0]\n",
      " [ 2  3  9  3 13]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78        36\n",
      "           1       0.35      0.29      0.32        24\n",
      "           2       0.53      0.57      0.55        30\n",
      "           3       0.77      1.00      0.87        27\n",
      "           4       0.59      0.43      0.50        30\n",
      "\n",
      "    accuracy                           0.63       147\n",
      "   macro avg       0.60      0.62      0.60       147\n",
      "weighted avg       0.61      0.63      0.62       147\n",
      "\n",
      "---------------- Random Forest ----------------\n",
      "score :  0.5102040816326531\n",
      "confusion_matrix [[29  1  4  2  0]\n",
      " [ 3  8  6  4  3]\n",
      " [ 2  7 14  1  6]\n",
      " [ 7  1  8  7  4]\n",
      " [ 6  2  4  1 17]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70        36\n",
      "           1       0.42      0.33      0.37        24\n",
      "           2       0.39      0.47      0.42        30\n",
      "           3       0.47      0.26      0.33        27\n",
      "           4       0.57      0.57      0.57        30\n",
      "\n",
      "    accuracy                           0.51       147\n",
      "   macro avg       0.49      0.49      0.48       147\n",
      "weighted avg       0.50      0.51      0.50       147\n",
      "\n",
      "---------------- Neural Net ----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\ipykernel_launcher.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.5374149659863946\n",
      "confusion_matrix [[29  0  1  0  6]\n",
      " [ 8  3  7  4  2]\n",
      " [ 1  1 24  4  0]\n",
      " [ 0  1  5 20  1]\n",
      " [ 5  0 13  9  3]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73        36\n",
      "           1       0.60      0.12      0.21        24\n",
      "           2       0.48      0.80      0.60        30\n",
      "           3       0.54      0.74      0.62        27\n",
      "           4       0.25      0.10      0.14        30\n",
      "\n",
      "    accuracy                           0.54       147\n",
      "   macro avg       0.51      0.51      0.46       147\n",
      "weighted avg       0.51      0.54      0.48       147\n",
      "\n",
      "---------------- AdaBoost ----------------\n",
      "score : "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.5918367346938775\n",
      "confusion_matrix [[20  6  0  7  3]\n",
      " [ 1 15  4  2  2]\n",
      " [ 1  5 19  2  3]\n",
      " [ 0  2  7 15  3]\n",
      " [ 0  8  3  1 18]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69        36\n",
      "           1       0.42      0.62      0.50        24\n",
      "           2       0.58      0.63      0.60        30\n",
      "           3       0.56      0.56      0.56        27\n",
      "           4       0.62      0.60      0.61        30\n",
      "\n",
      "    accuracy                           0.59       147\n",
      "   macro avg       0.62      0.59      0.59       147\n",
      "weighted avg       0.64      0.59      0.60       147\n",
      "\n",
      "---------------- Naive Bayes ----------------\n",
      "score :  0.46938775510204084\n",
      "confusion_matrix [[25  0  0  9  2]\n",
      " [ 5  0 11  4  4]\n",
      " [ 2  0 25  2  1]\n",
      " [ 6  0  2 15  4]\n",
      " [ 3  3 15  5  4]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65        36\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.47      0.83      0.60        30\n",
      "           3       0.43      0.56      0.48        27\n",
      "           4       0.27      0.13      0.18        30\n",
      "\n",
      "    accuracy                           0.47       147\n",
      "   macro avg       0.36      0.44      0.38       147\n",
      "weighted avg       0.38      0.47      0.41       147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3.1\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1944x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_data_modeled.values, result.values, test_size = 0.2)\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=12),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    print(\"----------------\",name,\"----------------\")\n",
    "    clf.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_test)\n",
    "    score = clf.score(x_test, y_test)\n",
    "    print(\"score : \", score)\n",
    "    print(\"confusion_matrix\", confusion_matrix(y_test, preds))\n",
    "    print(\"classification_report\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
